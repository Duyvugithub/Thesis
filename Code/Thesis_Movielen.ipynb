{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xck0W_D8Llps"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SYdI8rC0FtBC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import sys\n",
        "import scipy.optimize\n",
        "from scipy.sparse import csr_matrix\n",
        "import argparse\n",
        "import pickle\n",
        "import os\n",
        "import itertools\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KMSgJLJziQfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ee7410-d4ab-4a14-e33b-1c7ed77ef8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RAfOaC4_s4VZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6An7R8voiUdS"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/Thesis/data/Coat/test.ascii', 'r') as f:\n",
        "  file = np.loadtxt(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IIJtxWZnJjlr"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/Thesis/data/R3/ydata-ymusic-rating-study-v1_0-train.txt', 'r') as f:\n",
        "  data_r3 = np.loadtxt(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m1zbtZHlJ0zX"
      },
      "outputs": [],
      "source": [
        "r3_df = pd.DataFrame(data_r3, columns=[\"userId\", \"itemId\", \"rating\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ThtIEaiRLlwi"
      },
      "outputs": [],
      "source": [
        "num_users, num_items = 15400, 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TKAmjG0GMeh0"
      },
      "outputs": [],
      "source": [
        "n = len(r3_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Tc2Nuy99LSKc"
      },
      "outputs": [],
      "source": [
        "temp = r3_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PyUry88cKde6"
      },
      "outputs": [],
      "source": [
        "temp[\"count\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M_U1IbnlK6Wb"
      },
      "outputs": [],
      "source": [
        "temp[\"propensity\"] = temp.groupby([\"itemId\"])['count'].transform(sum) / num_users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3wjc70DkOpz6"
      },
      "outputs": [],
      "source": [
        "temp = temp[['itemId','propensity']].drop_duplicates().set_index('itemId').to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PXcegfYGrF4X"
      },
      "outputs": [],
      "source": [
        "raw_matrix = np.ma.array(file, dtype= int, copy= False, mask= file, fill_value= 0, hard_mask= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2Z8F9YhXr3Ar"
      },
      "outputs": [],
      "source": [
        "num_user, num_item = raw_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UCcSEU6ktuMZ"
      },
      "outputs": [],
      "source": [
        "po = n/(num_users*num_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B2f7OtCKuAaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba39a75-0e8c-4daa-c87a-8c7657c3c5c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02024051948051948"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "po"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ISD8p-FBt6QO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366cc24f-fe08-4fa1-e89e-a706dfad5968"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rating\n",
              "1.0    0.313900\n",
              "2.0    0.127210\n",
              "3.0    0.157621\n",
              "4.0    0.155532\n",
              "5.0    0.245736\n",
              "Name: userId, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "r3_df.groupby([\"rating\"])[\"userId\"].count()/n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5jb8R8A2dWRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e661f64-1358-4d5f-c054-48ca43562e14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rating\n",
              "1.0    97844\n",
              "2.0    39652\n",
              "3.0    49131\n",
              "4.0    48480\n",
              "5.0    76597\n",
              "Name: userId, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "r3_df.groupby([\"rating\"])[\"userId\"].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcu0OQ7cLqEi"
      },
      "source": [
        "# Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tKEHcNCXHHVH"
      },
      "outputs": [],
      "source": [
        "class Jitter:\n",
        "  def __init__(self, cut_off, num_users, num_items):\n",
        "      self.jitter = 1e-7 * np.random.standard_normal((num_users, num_items)) #create a dataset with standard normal (mean = 0, std = 1)\n",
        "      discountParams = 2.0 + np.array(range(num_items), dtype = np.longdouble)\n",
        "      self.discountParams = np.reciprocal(np.log2(discountParams)) # calculate 1/x\n",
        "      self.cutOff = min(cut_off, num_items)\n",
        "      self.discountParams[self.cutOff:] = 0.0\n",
        "\n",
        "      print(\"Jitter.init: [DBG]\\t (NumUsers, NumItems)\", num_users, num_items, \"\\t Sum DiscountFactors\",\\\n",
        "                self.discountParams.sum(dtype = np.longdouble), \"\\t [Requested/Set] Cut-off:\", \\\n",
        "                cut_off, self.cutOff)\n",
        "  def rank(self, predicted_matrix):\n",
        "    transformedPredictions = -np.ma.add(predicted_matrix, self.jitter)\n",
        "    sortedPredictions = np.ma.argsort(transformedPredictions, axis = 1)\n",
        "    return sortedPredictions\n",
        "dcgJitter = None              "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ekdcJUy0v_c0"
      },
      "outputs": [],
      "source": [
        "def SET_PROPENSITIES(observed_ratings, inverse_propensities= None, verbose = False):\n",
        "    numObservations = np.ma.count(observed_ratings)\n",
        "    numUsers, numItems = np.shape(observed_ratings)\n",
        "    scale = numUsers * numItems\n",
        "    inversePropensities = None\n",
        "    if inverse_propensities is None:\n",
        "        inversePropensities = np.ones((numUsers, numItems), dtype = np.longdouble) * scale / numObservations\n",
        "    else:\n",
        "        inversePropensities = np.array(inverse_propensities, dtype = np.longdouble, copy = True)\n",
        "\n",
        "    inversePropensities = np.ma.array(inversePropensities, dtype = np.longdouble, copy = False, \n",
        "                            mask = np.ma.getmask(observed_ratings), fill_value = 0, hard_mask = True)\n",
        " \n",
        "    if verbose:\n",
        "        print(\"Metrics.SET_PROPENSITIES: [LOG]\\t NumUsers, NumItems, NumObservations\", \\\n",
        "            numUsers, numItems, numObservations)\n",
        "        print(\"Metrics.SET_PROPENSITIES: [DBG]\\t Sum of observed inverse propensities \", \\\n",
        "            np.ma.sum(inversePropensities, dtype = np.longdouble), \\\n",
        "            \"(=? NumUsers * NumItems)\", numUsers * numItems)\n",
        "    return inversePropensities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G2EIXEmsINcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2b00a0-aee1-4424-d9a1-e754ede0e137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 290 300 82360\n",
            "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  86999.99999999999998 (=? NumUsers * NumItems) 87000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "masked_array(\n",
              "  data=[[1.0563380281690140845, 1.0563380281690140845,\n",
              "         1.0563380281690140845, ..., 1.0563380281690140845,\n",
              "         1.0563380281690140845, 1.0563380281690140845],\n",
              "        [1.0563380281690140845, --, 1.0563380281690140845, ...,\n",
              "         1.0563380281690140845, 1.0563380281690140845,\n",
              "         1.0563380281690140845],\n",
              "        [1.0563380281690140845, 1.0563380281690140845,\n",
              "         1.0563380281690140845, ..., 1.0563380281690140845,\n",
              "         1.0563380281690140845, 1.0563380281690140845],\n",
              "        ...,\n",
              "        [1.0563380281690140845, 1.0563380281690140845,\n",
              "         1.0563380281690140845, ..., 1.0563380281690140845,\n",
              "         1.0563380281690140845, 1.0563380281690140845],\n",
              "        [1.0563380281690140845, 1.0563380281690140845,\n",
              "         1.0563380281690140845, ..., 1.0563380281690140845,\n",
              "         1.0563380281690140845, 1.0563380281690140845],\n",
              "        [1.0563380281690140845, --, 1.0563380281690140845, ...,\n",
              "         1.0563380281690140845, 1.0563380281690140845,\n",
              "         1.0563380281690140845]],\n",
              "  mask=[[False, False, False, ..., False, False, False],\n",
              "        [False,  True, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False, False, False, ..., False, False, False],\n",
              "        [False,  True, False, ..., False, False, False]],\n",
              "  fill_value=0.0,\n",
              "  dtype=float128)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "SET_PROPENSITIES(raw_matrix, verbose= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "W5mi9xCxuehz"
      },
      "outputs": [],
      "source": [
        "def ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MSE'):\n",
        "    delta = np.ma.subtract(predicted_ratings, observed_ratings)\n",
        "    rectifiedDelta = None\n",
        "    if mode == 'MSE':\n",
        "        rectifiedDelta = np.square(delta)\n",
        "    elif mode == 'MAE':\n",
        "        rectifiedDelta = np.ma.abs(delta)\n",
        "    else:\n",
        "        print(\"Metrics.ITEMWISE_METRICS: [ERR]\\t Unrecognized itemwise metric \", mode)\n",
        "        sys.exit(0)\n",
        "\n",
        "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
        "\n",
        "    numUsers, numItems = np.shape(observed_ratings)\n",
        "    scale = numUsers * numItems\n",
        "\n",
        "    observedError = np.ma.multiply(rectifiedDelta, inversePropensities)\n",
        "    cumulativeError = np.ma.sum(observedError, dtype = np.longdouble)\n",
        "    vanillaMetric = cumulativeError / scale\n",
        "    \n",
        "    globalNormalizer = np.ma.sum(inversePropensities, dtype = np.longdouble)\n",
        "    selfNormalizedMetric = cumulativeError / globalNormalizer\n",
        "    \n",
        "    perUserNormalizer = np.ma.sum(inversePropensities, axis = 1, dtype = np.longdouble)\n",
        "    perUserNormalizer = np.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
        "\n",
        "    perUserError = np.ma.sum(observedError, axis = 1, dtype = np.longdouble)\n",
        "    perUserEstimate = np.ma.divide(perUserError, perUserNormalizer)\n",
        "    userNormalizedMetric = np.ma.sum(perUserEstimate, dtype = np.longdouble) / numUsers\n",
        "\n",
        "    perItemNormalizer = np.ma.sum(inversePropensities, axis = 0, dtype = np.longdouble)\n",
        "    perItemNormalizer = np.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
        "\n",
        "    perItemError = np.ma.sum(observedError, axis = 0, dtype = np.longdouble)\n",
        "    perItemEstimate = np.ma.divide(perItemError, perItemNormalizer)\n",
        "    itemNormalizedMetric = np.ma.sum(perItemEstimate, dtype = np.longdouble) / numItems\n",
        "   \n",
        "    if verbose:\n",
        "        print(\"Metrics.ITEMWISE_METRICS: [LOG]\\t Vanilla, SelfNormalized, UserNormalized, ItemNormalized\", \\\n",
        "            vanillaMetric, selfNormalizedMetric, userNormalizedMetric, itemNormalizedMetric)\n",
        "\n",
        "    return vanillaMetric, selfNormalizedMetric, userNormalizedMetric, itemNormalizedMetric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_gifZDUzCvjX"
      },
      "outputs": [],
      "source": [
        "def MSE(observed_ratings, predicted_ratings, inverse_propensities, verbose = False):\n",
        "    return ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MSE')\n",
        "\n",
        "\n",
        "def MAE(observed_ratings, predicted_ratings, inverse_propensities, verbose = False):\n",
        "    return ITEMWISE_METRICS(observed_ratings, predicted_ratings, inverse_propensities, verbose, mode = 'MAE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jku77jSxx1sF"
      },
      "outputs": [],
      "source": [
        "def DCG(observed_ratings, predicted_ratings, inverse_propensities, cut_off = 50, verbose = False):\n",
        "    global dcgJitter\n",
        "    numUsers, numItems = np.shape(observed_ratings)\n",
        "    scale = numUsers * numItems\n",
        "\n",
        "    if dcgJitter is None or dcgJitter.cutOff != cut_off:\n",
        "        dcgJitter = Jitter(cut_off, numUsers, numItems)\n",
        " \n",
        "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
        "    \n",
        "    predictedRankings = dcgJitter.rank(predicted_ratings)\n",
        "    weightedGain = np.ma.multiply(observed_ratings, inversePropensities)\n",
        " \n",
        "    perUserNormalizer = np.ma.sum(inversePropensities, axis = 1, dtype = np.longdouble)\n",
        "    perUserNormalizer = np.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
        "\n",
        "    staticIndices = np.ogrid[0:numUsers, 0:numItems]\n",
        "    rankedGains = weightedGain[staticIndices[0], predictedRankings]\n",
        "    perUserDCG = np.ma.dot(rankedGains, dcgJitter.discountParams)\n",
        "\n",
        "    dcgValue = np.ma.sum(perUserDCG, dtype = np.longdouble) / numUsers\n",
        "    snDCGValue = dcgValue * scale / np.ma.sum(inversePropensities, dtype = np.longdouble)\n",
        "\n",
        "    perUserNormalizedEstimates = np.ma.divide(perUserDCG, perUserNormalizer)\n",
        "    uDCGValue = numItems * np.ma.sum(perUserNormalizedEstimates, dtype = np.longdouble) / numUsers\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"Metrics.DCG: [LOG]\\t DCG, SN-DCG, UN-DCG, IN-DCG\", dcgValue, snDCGValue, uDCGValue, 0.0)\n",
        "    return dcgValue, snDCGValue, uDCGValue, 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X1LFV9qfzMuV"
      },
      "outputs": [],
      "source": [
        "def CG(observed_ratings, selected_items, inverse_propensities, verbose = False):\n",
        "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, verbose)\n",
        "\n",
        "    clippedSelections = np.clip(selected_items, 0, 1)\n",
        "    weightedGain = np.ma.multiply(observed_ratings, inversePropensities)\n",
        "    cumulativeGain = np.ma.multiply(weightedGain, clippedSelections)\n",
        "    \n",
        "    numUsers, numItems = np.shape(observed_ratings)\n",
        "    scale = numUsers * numItems\n",
        "\n",
        "    globalGain = np.ma.sum(cumulativeGain, dtype = np.longdouble)\n",
        "    globalNormalizer = np.ma.sum(inversePropensities, dtype = np.longdouble)\n",
        "\n",
        "    cg = globalGain / numUsers\n",
        "    snCG = numItems * globalGain / globalNormalizer\n",
        "\n",
        "    perUserNormalizer = np.ma.sum(inversePropensities, axis = 1, dtype = np.longdouble)\n",
        "    perUserNormalizer = np.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
        "\n",
        "    perUserGain = np.ma.sum(cumulativeGain, axis = 1, dtype = np.longdouble)\n",
        "    perUserEstimate = np.ma.divide(perUserGain, perUserNormalizer)\n",
        "    unCG = numItems * np.ma.sum(perUserEstimate, dtype = np.longdouble) / numUsers\n",
        "\n",
        "    perItemNormalizer = np.ma.sum(inversePropensities, axis = 0, dtype = np.longdouble)\n",
        "    perItemNormalizer = np.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
        "\n",
        "    perItemGain = np.ma.sum(cumulativeGain, axis = 0, dtype = np.longdouble)\n",
        "    perItemEstimate = np.ma.divide(perItemGain, perItemNormalizer)\n",
        "    inCG = np.ma.sum(perItemEstimate, dtype = np.longdouble)\n",
        "       \n",
        "    if verbose:\n",
        "        print(\"Metrics.CG: [LOG]\\t CG, SN-CG, UN-CG, IN-CG\", cg, snCG, unCG, inCG)\n",
        "    return cg, snCG, unCG, inCG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NtOhyGTIKZY9"
      },
      "outputs": [],
      "source": [
        "x = 1e-7 * np.random.standard_normal((5, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "318IJo3TGp3d"
      },
      "outputs": [],
      "source": [
        "y = np.array(range(20)).reshape(5,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hv55osg4H52d"
      },
      "outputs": [],
      "source": [
        "shape = (5,3)\n",
        "a = np.random.randint(0,5, size=shape)\n",
        "b = np.random.randint(0,5, size=shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "12uLRxKLtSza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2590f38e-9e0f-4f9f-e8c0-a9beee11f7fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 3, 3],\n",
              "       [3, 1, 0],\n",
              "       [3, 3, 2],\n",
              "       [4, 1, 2],\n",
              "       [0, 3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TT7xL1rgth8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12e5fb2-ddf9-40ca-d3cc-a322ffecc579"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4, 2, 0],\n",
              "       [1, 3, 1],\n",
              "       [0, 4, 3],\n",
              "       [0, 1, 0],\n",
              "       [2, 2, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vR7aqL3ctrOE"
      },
      "outputs": [],
      "source": [
        "inversePropensities = np.random.random(shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "swM88owKvNrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b62d4c-71c1-491b-c368-e0d2343c9633"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.68268509, 0.60340346, 0.98554577],\n",
              "       [0.00675616, 0.00654541, 0.62218479],\n",
              "       [0.39055642, 0.07475298, 0.12460294],\n",
              "       [0.90466403, 0.4269031 , 0.57831279],\n",
              "       [0.33550283, 0.47317894, 0.35132238]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "inversePropensities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nZ5lcRKP0HCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76204f77-9be0-40f3-fd89-ce39e3a4f49c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02192497, 0.57824025, 0.71081227],\n",
              "       [0.5079452 , 0.01267618, 0.29790505],\n",
              "       [0.90212526, 0.71431484, 0.17000135],\n",
              "       [0.65050905, 0.37871847, 0.76298707],\n",
              "       [0.0506962 , 0.84838684, 0.07018855]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "obs = np.random.random(shape)\n",
        "obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wSuBxt6C0RyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36220a2-9fb9-411a-b369-f0d50e3a5ef7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True],\n",
              "       [False, False,  True],\n",
              "       [False, False, False],\n",
              "       [ True,  True, False],\n",
              "       [ True, False,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "obs = obs < inversePropensities\n",
        "obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nkF5qgIy0X_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb4801b-9c5a-48ad-a783-91d438934a46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.46480422,   1.65726593,   1.01466621],\n",
              "       [148.01311645, 152.77877384,   1.60723955],\n",
              "       [  2.56044951,  13.37739283,   8.02549268],\n",
              "       [  1.10538273,   2.34245195,   1.72916804],\n",
              "       [  2.98060075,   2.11336538,   2.84638858]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "inversePropensities = np.reciprocal(inversePropensities)\n",
        "inversePropensities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "br_X15d70dh_"
      },
      "outputs": [],
      "source": [
        "observed_a = np.ma.array(a, dtype = np.longdouble, copy = True, \n",
        "                        mask = np.logical_not(obs), fill_value = 0, hard_mask = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UKIn9uiA0xxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4585f48f-df3f-412c-c901-f731448708f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "masked_array(\n",
              "  data=[[2.0, 3.0, 3.0],\n",
              "        [--, --, 0.0],\n",
              "        [--, --, --],\n",
              "        [4.0, 1.0, --],\n",
              "        [0.0, --, 4.0]],\n",
              "  mask=[[False, False, False],\n",
              "        [ True,  True, False],\n",
              "        [ True,  True,  True],\n",
              "        [False, False,  True],\n",
              "        [False,  True, False]],\n",
              "  fill_value=0.0,\n",
              "  dtype=float128)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "observed_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LsDfg9wC0z6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2875fa60-a8cc-4187-f5d0-4797932dba0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 5 3 8\n",
            "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  15.01879991760127897 (=? NumUsers * NumItems) 15\n",
            "Metrics.ITEMWISE_METRICS: [LOG]\t Vanilla, SelfNormalized, UserNormalized, ItemNormalized 3.9499866203768751276 3.9450421891708763488 2.830835294547432776 3.6166787421628750912\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.9499866203768751276,\n",
              " 3.9450421891708763488,\n",
              " 2.830835294547432776,\n",
              " 3.6166787421628750912)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "MSE(observed_a, b, inversePropensities, verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7j6lTtwq05NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad92f03-6b49-4912-e717-226f24e25534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 5 3 8\n",
            "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  15.01879991760127897 (=? NumUsers * NumItems) 15\n",
            "Metrics.ITEMWISE_METRICS: [LOG]\t Vanilla, SelfNormalized, UserNormalized, ItemNormalized 1.6875748095709399118 1.6854623726558741395 1.225413652847067553 1.5680866680805637024\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.6875748095709399118,\n",
              " 1.6854623726558741395,\n",
              " 1.225413652847067553,\n",
              " 1.5680866680805637024)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "MAE(observed_a, b, inversePropensities, verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "JNDv7I4Q107j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a22cd4-80e1-4541-8d9c-aeffa23d93d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jitter.init: [DBG]\t (NumUsers, NumItems) 5 3 \t Sum DiscountFactors 2.1309297535714574372 \t [Requested/Set] Cut-off: 50 3\n",
            "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 5 3 8\n",
            "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  15.01879991760127897 (=? NumUsers * NumItems) 15\n",
            "Metrics.DCG: [LOG]\t DCG, SN-DCG, UN-DCG, IN-DCG 4.7054469258736597295 4.699556840449461275 3.0653666773592650552 0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.7054469258736597295, 4.699556840449461275, 3.0653666773592650552, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "DCG(observed_a, b, inversePropensities, cut_off = 50, verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "lHAlAFA7124k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8db129-fea6-4d77-d4f1-ee97c1bafdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics.SET_PROPENSITIES: [LOG]\t NumUsers, NumItems, NumObservations 5 3 8\n",
            "Metrics.SET_PROPENSITIES: [DBG]\t Sum of observed inverse propensities  15.01879991760127897 (=? NumUsers * NumItems) 15\n",
            "Metrics.CG: [LOG]\t CG, SN-CG, UN-CG, IN-CG 4.3258824966303767836 4.3204675343873445836 2.7260341495394187824 4.4385772961738795724\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.3258824966303767836,\n",
              " 4.3204675343873445836,\n",
              " 2.7260341495394187824,\n",
              " 4.4385772961738795724)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "CG(observed_a, b, inversePropensities, verbose = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bpm1mQaLvuK"
      },
      "source": [
        "# Matrix Fatorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "MwB2ANFP19W8"
      },
      "outputs": [],
      "source": [
        "def PREDICTED_SCORES(user_vectors, item_vectors, user_biases, item_biases, global_bias, use_bias = True):\n",
        "    rawScores = np.dot(user_vectors, item_vectors.T)\n",
        "    if use_bias:\n",
        "        biasedScores = rawScores + user_biases[:,None] + item_biases[None,:] + global_bias\n",
        "        return biasedScores\n",
        "    else:\n",
        "        return rawScores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "mmw14Rsr2VKL"
      },
      "outputs": [],
      "source": [
        "def GENERATE_MATRIX(observed_ratings, inverse_propensities, l2_regularization, num_dimensions, normalization,\n",
        "        bias_mode = 'Regularized', mode = 'MSE', start_vec = None, verbose = False):\n",
        "\n",
        "    metricMode = None\n",
        "    if mode == 'MSE':\n",
        "        metricMode = 1\n",
        "    elif mode == 'MAE':\n",
        "        metricMode = 2\n",
        "    else:\n",
        "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Metric not supported:\", mode)\n",
        "        sys.exit(0)\n",
        "\n",
        "    inversePropensities = SET_PROPENSITIES(observed_ratings, inverse_propensities, False)\n",
        "\n",
        "    numUsers, numItems = np.shape(observed_ratings)\n",
        "    scale = numUsers * numItems\n",
        "    numObservations = np.ma.count(observed_ratings)\n",
        "\n",
        "    perUserNormalizer = np.ma.sum(inversePropensities, axis = 1, dtype = np.longdouble)\n",
        "    perUserNormalizer = np.ma.masked_less_equal(perUserNormalizer, 0.0, copy = False)\n",
        "\n",
        "    perItemNormalizer = np.ma.sum(inversePropensities, axis = 0, dtype = np.longdouble)\n",
        "    perItemNormalizer = np.ma.masked_less_equal(perItemNormalizer, 0.0, copy = False)\n",
        "\n",
        "    globalNormalizer = np.ma.sum(inversePropensities, dtype = np.longdouble)\n",
        "\n",
        "    normalizedPropensities = None\n",
        "    if normalization == 'Vanilla':\n",
        "        normalizedPropensities = inversePropensities\n",
        "    elif normalization == 'SelfNormalized':\n",
        "        normalizedPropensities = scale * np.ma.divide(inversePropensities, globalNormalizer)\n",
        "    elif normalization == 'UserNormalized':\n",
        "        normalizedPropensities = numItems * np.ma.divide(inversePropensities, perUserNormalizer[:, None])\n",
        "    elif normalization == 'ItemNormalized':\n",
        "        normalizedPropensities = numUsers * np.ma.divide(inversePropensities, perItemNormalizer[None, :])\n",
        "    else:\n",
        "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Normalization not supported:\", normalization)\n",
        "        sys.exit(0)\n",
        "    \n",
        "    useBias = None\n",
        "    regularizeBias = None\n",
        "    if bias_mode == 'None':\n",
        "        useBias = False\n",
        "        regularizeBias = False\n",
        "    elif bias_mode == 'Regularized':\n",
        "        useBias = True\n",
        "        regularizeBias = True\n",
        "    elif bias_mode == 'Free':\n",
        "        useBias = True\n",
        "        regularizeBias = False\n",
        "    else:\n",
        "        print(\"MF.GENERATE_MATRIX: [ERR]\\t Bias mode not supported:\", bias_mode)\n",
        "        sys.exit(0)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"MF.GENERATE_MATRIX: [LOG]\\t Lamda:\", l2_regularization, \"\\t NumDims:\", num_dimensions,\\\n",
        "            \"\\t Normalization:\", normalization, \"\\t Metric:\", mode, \"\\t BiasMode:\", bias_mode)\n",
        "\n",
        "    normalizedPropensities = np.ma.filled(normalizedPropensities, 0.0)\n",
        "    observedRatings = np.ma.filled(observed_ratings, 0)\n",
        "    \n",
        "    def Mat2Vec(user_vectors, item_vectors, user_biases, item_biases, global_bias):\n",
        "        allUserParams = np.concatenate((user_vectors, user_biases[:,None]), axis = 1)\n",
        "        allItemParams = np.concatenate((item_vectors, item_biases[:,None]), axis = 1)\n",
        "        \n",
        "        allParams = np.concatenate((allUserParams, allItemParams), axis = 0)\n",
        "        paramVector = np.reshape(allParams, (numUsers + numItems)*(num_dimensions + 1))\n",
        "        paramVector = np.concatenate((paramVector, [global_bias]))\n",
        "        return paramVector.astype(float)\n",
        "        \n",
        "    def Vec2Mat(paramVector):\n",
        "        globalBias = paramVector[-1]\n",
        "        remainingParams = paramVector[:-1]\n",
        "        allParams = np.reshape(remainingParams, (numUsers + numItems, num_dimensions + 1))\n",
        "        allUserParams = allParams[0:numUsers,:]\n",
        "        allItemParams = allParams[numUsers:, :]\n",
        "        \n",
        "        userVectors = (allUserParams[:,0:-1]).astype(np.longdouble)\n",
        "        userBiases = (allUserParams[:,-1]).astype(np.longdouble)\n",
        "        \n",
        "        itemVectors = (allItemParams[:,0:-1]).astype(np.longdouble)\n",
        "        itemBiases = (allItemParams[:,-1]).astype(np.longdouble)\n",
        "        return userVectors, itemVectors, userBiases, itemBiases, globalBias\n",
        "    \n",
        "    def Objective(paramVector):\n",
        "        userVectors, itemVectors, userBiases, itemBiases, globalBias = Vec2Mat(paramVector)\n",
        "        biasedScores = PREDICTED_SCORES(userVectors, itemVectors, userBiases, itemBiases, globalBias, useBias)\n",
        "\n",
        "        delta = np.subtract(biasedScores, observedRatings)\n",
        "        loss = None\n",
        "        if metricMode == 1:\n",
        "            loss = np.square(delta)\n",
        "        elif metricMode == 2:\n",
        "            loss = np.abs(delta)\n",
        "        else:\n",
        "            sys.exit(0)\n",
        "\n",
        "        weightedLoss = np.multiply(loss, normalizedPropensities)\n",
        "        objective = np.sum(weightedLoss, dtype = np.longdouble)\n",
        "\n",
        "        gradientMultiplier = None\n",
        "        if metricMode == 1:\n",
        "            gradientMultiplier = np.multiply(normalizedPropensities, 2 * delta)\n",
        "        elif metricMode == 2:\n",
        "            gradientMultiplier = np.zeros(np.shape(delta), dtype = np.int)\n",
        "            gradientMultiplier[delta > 0] = 1\n",
        "            gradientMultiplier[delta < 0] = -1\n",
        "            gradientMultiplier = np.multiply(normalizedPropensities, gradientMultiplier)\n",
        "        else:\n",
        "            sys.exit(0)\n",
        "\n",
        "        userVGradient = np.dot(gradientMultiplier, itemVectors)\n",
        "        itemVGradient = np.dot(gradientMultiplier.T, userVectors)\n",
        "\n",
        "        userBGradient = None\n",
        "        itemBGradient = None\n",
        "        globalBGradient = None\n",
        "        if useBias:\n",
        "            userBGradient = np.sum(gradientMultiplier, axis = 1, dtype = np.longdouble)\n",
        "            itemBGradient = np.sum(gradientMultiplier, axis = 0, dtype = np.longdouble)\n",
        "            globalBGradient = np.sum(gradientMultiplier, dtype = np.longdouble)\n",
        "        else:\n",
        "            userBGradient = np.zeros(np.shape(userBiases), dtype = np.longdouble)\n",
        "            itemBGradient = np.zeros(np.shape(itemBiases), dtype = np.longdouble)\n",
        "            globalBGradient = 0.0\n",
        "\n",
        "        if l2_regularization > 0:\n",
        "            scaledPenalty = 1.0 * l2_regularization * scale / (numUsers + numItems)\n",
        "            if regularizeBias:\n",
        "                scaledPenalty /= (num_dimensions + 1)\n",
        "            else:\n",
        "                scaledPenalty /= num_dimensions\n",
        "\n",
        "            userVGradient += 2 * scaledPenalty * userVectors\n",
        "            itemVGradient += 2 * scaledPenalty * itemVectors\n",
        "          \n",
        "            objective += scaledPenalty * np.sum(np.square(userVectors), dtype = np.longdouble)\n",
        "            objective += scaledPenalty * np.sum(np.square(itemVectors), dtype = np.longdouble)\n",
        " \n",
        "            if regularizeBias:\n",
        "                userBGradient += 2 * scaledPenalty * userBiases\n",
        "                itemBGradient += 2 * scaledPenalty * itemBiases\n",
        "                globalBGradient += 2 * scaledPenalty * globalBias\n",
        "                objective += scaledPenalty * np.sum(np.square(userBiases), dtype = np.longdouble)\n",
        "                objective += scaledPenalty * np.sum(np.square(itemBiases), dtype = np.longdouble)\n",
        "                objective += scaledPenalty * globalBias * globalBias\n",
        "            \n",
        "        gradient = Mat2Vec(userVGradient, itemVGradient, userBGradient, itemBGradient, globalBGradient)\n",
        "\n",
        "        if verbose:\n",
        "            print(\".\")\n",
        "            sys.stdout.flush()\n",
        "        \n",
        "        return objective, gradient\n",
        "    \n",
        "    def ObjectiveOnly(paramVector):\n",
        "        objective, gradient = Objective(paramVector)\n",
        "        return objective\n",
        "    def GradientOnly(paramVector):\n",
        "        objective, gradient = Objective(paramVector)\n",
        "        return gradient\n",
        "    \n",
        "    userVectorsInit = None\n",
        "    itemVectorsInit = None\n",
        "    userBiasesInit = None\n",
        "    itemBiasesInit = None\n",
        "    globalBiasInit = None\n",
        "    if start_vec is None:\n",
        "        userVectorsInit = np.random.standard_normal((numUsers, num_dimensions))\n",
        "        itemVectorsInit = np.random.standard_normal((numItems, num_dimensions))\n",
        "        userBiasesInit = np.zeros(numUsers, dtype = float)\n",
        "        itemBiasesInit = np.zeros(numItems, dtype = float)\n",
        "        globalBiasInit = 0\n",
        "    else:\n",
        "        userVectorsInit = start_vec[0]\n",
        "        itemVectorsInit = start_vec[1]\n",
        "        userBiasesInit = start_vec[2]\n",
        "        itemBiasesInit = start_vec[3]\n",
        "        globalBiasInit = start_vec[4]\n",
        "    \n",
        "    startVector = Mat2Vec(userVectorsInit, itemVectorsInit, userBiasesInit, itemBiasesInit, globalBiasInit)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"MF.GENERATE_MATRIX: [DBG]\\t Checking gradients\")\n",
        "        print(scipy.optimize.check_grad(ObjectiveOnly, GradientOnly, startVector))\n",
        "\n",
        "    ops = {'maxiter': 2000, 'disp': False, 'gtol': 1e-5,\\\n",
        "            'ftol': 1e-5, 'maxcor': 50}\n",
        "\n",
        "    result = scipy.optimize.minimize(fun = Objective, x0 = startVector,\n",
        "                    method = 'L-BFGS-B', jac = True, tol = 1e-5, options = ops)\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"MF.GENERATE_MATRIX: [DBG]\\t Optimization result:\", result['message'])\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    return Vec2Mat(result['x'])\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "j9cvQ_TK8vS5"
      },
      "outputs": [],
      "source": [
        "rows = [2,1,4,3,0,4,3]\n",
        "cols = [0,2,1,1,0,0,0]\n",
        "vals = [1,2,3,4,5,4,5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "fgvctp9C9M4E"
      },
      "outputs": [],
      "source": [
        "checkY = scipy.sparse.coo_matrix((vals, (rows,cols)), dtype = int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "YLslp1MI9M7j"
      },
      "outputs": [],
      "source": [
        "checkY = checkY.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Ks8_SD4c9a4h"
      },
      "outputs": [],
      "source": [
        "checkY = np.ma.array(checkY, dtype = int, mask = checkY <= 0, hard_mask = True, copy = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CM-F2-eH927t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da490938-ea61-4eaf-ad80-66181d1359f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "masked_array(\n",
              "  data=[[5, --, --],\n",
              "        [--, --, 2],\n",
              "        [1, --, --],\n",
              "        [5, 4, --],\n",
              "        [4, 3, --]],\n",
              "  mask=[[False,  True,  True],\n",
              "        [ True,  True, False],\n",
              "        [False,  True,  True],\n",
              "        [False, False,  True],\n",
              "        [False, False,  True]],\n",
              "  fill_value=999999)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "checkY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "MaFMf2Xk9-Z9"
      },
      "outputs": [],
      "source": [
        "randomPropensities = np.random.random(size = np.shape(checkY))\n",
        "randomInvPropensities = np.reciprocal(randomPropensities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "5C_Bjwix-XkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51fb8dc-18d1-4045-eb85-afac95e7968d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01122689, 0.48025187, 0.11986694],\n",
              "       [0.99850098, 0.69313106, 0.55415292],\n",
              "       [0.43642062, 0.83753065, 0.12270462],\n",
              "       [0.89209186, 0.31989718, 0.86191889],\n",
              "       [0.23631792, 0.14301066, 0.76996319]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "randomPropensities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "7w9jdUSg-cWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57893df5-b9ec-441a-b958-85bcb26bf0e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[89.07183779,  2.08224073,  8.34258352],\n",
              "       [ 1.00150127,  1.4427286 ,  1.80455603],\n",
              "       [ 2.29136744,  1.19398616,  8.14965245],\n",
              "       [ 1.12096079,  3.12600443,  1.16020197],\n",
              "       [ 4.23158773,  6.99248566,  1.29876339]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "randomInvPropensities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "jX70s6RI-eZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb250c5-13a2-43e3-db59-7d3736672c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MF.GENERATE_MATRIX: [LOG]\t Lamda: 1.0 \t NumDims: 5 \t Normalization: Vanilla \t Metric: MSE \t BiasMode: Regularized\n",
            "MF.GENERATE_MATRIX: [DBG]\t Checking gradients\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            "5.408484899420198e-07\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            "MF.GENERATE_MATRIX: [DBG]\t Optimization result: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n"
          ]
        }
      ],
      "source": [
        "userVectors, itemVectors, userBiases, itemBiases, globalBias = GENERATE_MATRIX(checkY, None, 1.0, 5, 'Vanilla',\n",
        "                                                'Regularized', 'MSE', None, verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "aSmU2YwI-kNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2668e9e5-4d55-4098-fb6e-06c43c7fb764"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.61613245e-01, -6.08841814e-01,  7.52760048e-01,\n",
              "         -2.04434348e-01, -2.64624416e-01],\n",
              "        [ 1.91199140e-04,  7.65018887e-05,  4.79501352e-04,\n",
              "         -1.32561965e-04,  2.53838751e-04],\n",
              "        [-1.13115783e-01,  4.21512452e-01, -5.17904340e-01,\n",
              "          1.38065587e-01,  1.82337926e-01],\n",
              "        [ 1.28644222e-01, -4.92916029e-01,  6.03576109e-01,\n",
              "         -1.59007624e-01, -2.09146464e-01],\n",
              "        [ 1.03132311e-01, -3.78422080e-01,  4.67139774e-01,\n",
              "         -1.26449351e-01, -1.64937728e-01]], dtype=float128),\n",
              " array([[ 2.42236250e-01, -9.06566332e-01,  1.11434637e+00,\n",
              "         -2.98702760e-01, -3.91101982e-01],\n",
              "        [ 8.74389510e-02, -3.40003602e-01,  4.14416726e-01,\n",
              "         -1.08345147e-01, -1.42876845e-01],\n",
              "        [ 1.88903886e-04,  2.23757105e-04,  1.99073120e-04,\n",
              "         -2.36440491e-04,  2.04460517e-04]], dtype=float128),\n",
              " array([ 0.67463379,  0.13672695, -0.46519977,  1.05374605,  0.30652761],\n",
              "       dtype=float128),\n",
              " array([0.92581739, 0.6438903 , 0.13672695], dtype=float128),\n",
              " 1.7064346309023115)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "userVectors, itemVectors, userBiases, itemBiases, globalBias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "HWkhnkmCInhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c025f5d-c96a-4faf-dde0-8cca9753eb18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "userVectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "24hakk6_Itlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fdf3ac-f186-4327-f124-4f69c6856d8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "itemVectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "2g9MnfLgIy26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e33a2e8-d9ac-48d5-b849-03c0b3e43914"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.59449974e+00,  5.93054227e-01,  3.83822923e-05],\n",
              "       [ 4.51611705e-04,  1.67515481e-04,  2.31934950e-07],\n",
              "       [-1.09920786e+00, -4.08845302e-01, -2.55158262e-05],\n",
              "       [ 1.27990983e+00,  4.76083667e-01,  2.89973552e-05],\n",
              "       [ 9.90880857e-01,  3.68539143e-01,  2.39769308e-05]],\n",
              "      dtype=float128)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "np.dot(userVectors, itemVectors.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "qj2EdVqP-sX0"
      },
      "outputs": [],
      "source": [
        "completeScores = PREDICTED_SCORES(userVectors, itemVectors, userBiases, itemBiases, globalBias, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "BRitOOd3-8oV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2428a86-0213-48ac-8b57-c55e64e27b2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.90138556, 3.61801295, 2.51783375],\n",
              "       [2.76943058, 2.48721939, 1.97988875],\n",
              "       [1.06784438, 1.47627985, 1.37793629],\n",
              "       [4.9659079 , 3.88015465, 2.89693663],\n",
              "       [3.92966049, 3.02539168, 2.14971316]], dtype=float128)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "completeScores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ViiOZqPR--1L"
      },
      "outputs": [],
      "source": [
        "def MF_TRAIN(params, train_observations, inv_propensities, normalization, metric, start_vector):\n",
        "    retVal = None\n",
        "    actualStart = None\n",
        "    if start_vector is not None:\n",
        "        actualStart = (start_vector[0][:,0:params[1]], start_vector[1][:,0:params[1]],\n",
        "                        start_vector[2], start_vector[3], start_vector[4])\n",
        "\n",
        "    tempInvPropensities = None\n",
        "    if inv_propensities is not None:\n",
        "        tempInvPropensities = (4.0 / 3.0) * inv_propensities\n",
        "        if params[2] >= 0:\n",
        "            tempInvPropensities = np.clip(tempInvPropensities, a_min = 0, a_max = params[2])\n",
        "\n",
        "    retVal = GENERATE_MATRIX(train_observations, tempInvPropensities, params[0], \n",
        "                                params[1], normalization, bias_mode = params[3], mode = metric, \n",
        "                                start_vec = actualStart, verbose = False)\n",
        "\n",
        "    return retVal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "jeWc7Wb4Yj1k"
      },
      "outputs": [],
      "source": [
        "def FINAL_TRAIN(approach_tuple, metric, observations, start_vector):\n",
        "    invP = approach_tuple[1]\n",
        "    normN = approach_tuple[2]\n",
        "    bestLambda = approach_tuple[3][0]\n",
        "    bestDims = approach_tuple[3][1]\n",
        "    bestClip = approach_tuple[3][2]\n",
        "    bestBias = approach_tuple[3][3]\n",
        "    actualStart = None\n",
        "    if start_vector is not None:\n",
        "        actualStart = (start_vector[0][:,0:bestDims], start_vector[1][:,0:bestDims],\n",
        "                        start_vector[2], start_vector[3], start_vector[4])\n",
        "\n",
        "    tempInvP = None\n",
        "    if bestClip < 0 or invP is None:\n",
        "        tempInvP = invP\n",
        "    else:\n",
        "        tempInvP = np.clip(invP, a_min = 0, a_max = bestClip)\n",
        "\n",
        "    retVal = GENERATE_MATRIX(observations, tempInvP, bestLambda, bestDims, normN, bias_mode = bestBias,\n",
        "                        mode = metric, start_vec = actualStart)\n",
        "\n",
        "    return retVal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "W4hLy4zhYmPQ"
      },
      "outputs": [],
      "source": [
        "def INIT_PARAMS(partial_observations, num_dimensions):\n",
        "    averageObservedRating = np.ma.mean(partial_observations, dtype = np.longdouble)\n",
        "    completeRatings = np.ma.filled(partial_observations.astype(float), averageObservedRating)\n",
        "    numUsers, numItems = np.shape(partial_observations)\n",
        "\n",
        "    u,s,vt = scipy.sparse.linalg.svds(completeRatings, k = num_dimensions, ncv = 50, tol = 1e-7, which = 'LM', \n",
        "                        v0 = None, maxiter = 2000, return_singular_vectors = True)\n",
        "            \n",
        "    startTuple = (u, np.transpose(np.multiply(vt, s[:,None])), \n",
        "                     np.zeros(numUsers, dtype = np.longdouble), \n",
        "                     np.zeros(numItems, dtype = np.longdouble), \n",
        "                     averageObservedRating)\n",
        "    return startTuple "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "zf5mJAnHY90V"
      },
      "outputs": [],
      "source": [
        "def TRAIN_HELPER(approach, gold_inv_propensities, nb_inv_propensities):\n",
        "    invP = None\n",
        "    if approach == 'Naive':\n",
        "        invP = None\n",
        "    elif approach.startswith('Gold'):\n",
        "        invP = gold_inv_propensities\n",
        "    elif approach.startswith('NB'):\n",
        "        invP = nb_inv_propensities\n",
        "    else:\n",
        "        print(\"TRAIN_HELPER: [ERR] Unrecognized approach\", approach)\n",
        "        sys.exit(0)\n",
        "\n",
        "    normN = None\n",
        "    if approach == 'Naive' or approach.endswith('-IPS'):\n",
        "        normN = 'Vanilla'\n",
        "    elif approach.endswith('-SNIPS'):\n",
        "        normN = 'SelfNormalized'\n",
        "    elif approach.endswith('-UNIPS'):\n",
        "        normN = 'UserNormalized'\n",
        "    elif approach.endswith('-INIPS'):\n",
        "        normN = 'ItemNormalized'\n",
        "    else:\n",
        "        print(\"TRAIN_HELPER: [ERR] Unrecognized approach\", approach)\n",
        "        sys.exit(0)\n",
        "        \n",
        "    return invP, normN   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "QBTC0MyuTnzq"
      },
      "outputs": [],
      "source": [
        "def learn(data, logger, lambdas=None, seed=None, numDims=None, approach=None, metric=None, raw_metric=None,\n",
        "          output_name=None, propensities_desc=None):\n",
        "    clipVals = [-1]\n",
        "    biasModes = ['Free', 'Regularized']\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    numBiasModes = len(biasModes)\n",
        "    numLambdas = len(lambdas)\n",
        "    numDimSettings = len(numDims)\n",
        "    numClipSettings = len(clipVals)\n",
        "    numParamSettings = numLambdas * numDimSettings * numClipSettings * numBiasModes\n",
        "\n",
        "    paramSettings = list(itertools.product(lambdas, numDims, clipVals, biasModes))\n",
        "    numApproaches = 1\n",
        "\n",
        "    selfMatrix = data.train\n",
        "\n",
        "    logger.log(\"Starting learning...\")\n",
        "    logger.log(\"\\t-metric: \" + raw_metric, 2)\n",
        "    logger.log(\"\\t-lambda values: \" + str(lambdas), 2)\n",
        "    logger.log(\"\\t-dimension values: \" + str(numDims), 2)\n",
        "    logger.log(\"\\t-propensity scoring method: \" + propensities_desc)\n",
        "    if data.propensities is not None:\n",
        "        invP = np.reciprocal(data.propensities)\n",
        "        invP = np.ma.array(invP, dtype=np.longdouble, copy=False,\n",
        "                              mask=np.ma.getmask(selfMatrix), fill_value=0, hard_mask=True)\n",
        "    else:\n",
        "        invP = None\n",
        "\n",
        "    foldScores = np.zeros((numApproaches, 4, numParamSettings), dtype=float)\n",
        "\n",
        "    observationIndices = np.ma.nonzero(selfMatrix)\n",
        "    numObservations = np.ma.count(selfMatrix)\n",
        "\n",
        "    shuffleIndices = np.random.permutation(numObservations)\n",
        "    fractionObservations = int(numObservations / 4)\n",
        "    firstFold = shuffleIndices[:fractionObservations]\n",
        "    secondFold = shuffleIndices[fractionObservations:2 * fractionObservations]\n",
        "    thirdFold = shuffleIndices[2 * fractionObservations:3 * fractionObservations]\n",
        "    fourthFold = shuffleIndices[3 * fractionObservations:]\n",
        "\n",
        "    logger.log(\"Split %d observations into folds. Fold sizes: %s\" %\n",
        "               (len(shuffleIndices), str([len(firstFold), len(secondFold), len(thirdFold), len(fourthFold)])),\n",
        "               2)\n",
        "\n",
        "    for fold in range(4):\n",
        "        logger.log(\"Learning on fold %d \" % fold)\n",
        "        trainObservations = np.ma.copy(selfMatrix)\n",
        "        testObservations = np.ma.copy(selfMatrix)\n",
        "\n",
        "        if fold == 0:\n",
        "            trainObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
        "                np.ma.masked\n",
        "        elif fold == 1:\n",
        "            trainObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
        "                np.ma.masked\n",
        "        elif fold == 2:\n",
        "            trainObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
        "                np.ma.masked\n",
        "        elif fold == 3:\n",
        "            trainObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "        # Get starting params by SVD\n",
        "        startTuple = INIT_PARAMS(trainObservations, 40)\n",
        "        normN = \"Vanilla\"\n",
        "        approachIndex = 0\n",
        "\n",
        "        modelsPerLambda = Parallel(n_jobs=-1, verbose=0)(delayed(MF_TRAIN)(param,\n",
        "                                                                                 trainObservations, invP, normN,\n",
        "                                                                                 raw_metric, startTuple)\n",
        "                                                         for param in paramSettings)\n",
        "\n",
        "        for lambdaIndex, eachModel in enumerate(modelsPerLambda):\n",
        "            selectedBiasMode = paramSettings[lambdaIndex][3]\n",
        "            selectedBias = True\n",
        "            if selectedBiasMode == 'None':\n",
        "                selectedBias = False\n",
        "            predictedY = PREDICTED_SCORES(eachModel[0], eachModel[1],\n",
        "                                             eachModel[2], eachModel[3], eachModel[4], use_bias=selectedBias)\n",
        "\n",
        "            score = None\n",
        "            if invP is not None:\n",
        "                score = metric(testObservations, predictedY, 4.0 * invP)\n",
        "            else:\n",
        "                score = metric(testObservations, predictedY, invP)\n",
        "            score = score[0]\n",
        "            foldScores[approachIndex, fold, lambdaIndex] = score\n",
        "\n",
        "            logger.log(\"\\tLambda/NumDims: \" + str(paramSettings[lambdaIndex]) +\n",
        "                       \", Test Fold Score: \" + str(score), 2)\n",
        "\n",
        "    eventualApproachParams = []\n",
        "\n",
        "    normN = \"Vanilla\"\n",
        "    approachIndex = 0\n",
        "    approachScores = foldScores[approachIndex, :, :]\n",
        "    allFoldScores = approachScores.sum(axis=0, dtype=float)\n",
        "    bestLambdaIndex = np.argmin(allFoldScores)\n",
        "    bestLambda = paramSettings[bestLambdaIndex]\n",
        "    logger.log(\"Retraining with best hyperparameter values: \" + str(bestLambda))\n",
        "    logger.log(\"Chosen from average cross-validation performance:\", 2)\n",
        "    for everyLambdaIndex, everyLambda in enumerate(paramSettings):\n",
        "        logger.log(\"\\t\" + str(everyLambda) + \": \" +  str(allFoldScores[everyLambdaIndex]), 2)\n",
        "    eventualApproachParams.append((approach, invP, normN, bestLambda))\n",
        "\n",
        "    finalModels = Parallel(n_jobs=-1, verbose=0)(delayed(FINAL_TRAIN)(approachTup,\n",
        "                                                                            raw_metric, selfMatrix, startTuple)\n",
        "                                                 for approachTup in eventualApproachParams)\n",
        "\n",
        "    for approachID, approachTuple in enumerate(eventualApproachParams):\n",
        "        resultTuple = finalModels[approachID]\n",
        "        finalBiasMode = approachTuple[3][3]\n",
        "        finalBias = True\n",
        "        if finalBiasMode == 'None':\n",
        "            finalBias = False\n",
        "\n",
        "        predictedY = PREDICTED_SCORES(resultTuple[0], resultTuple[1],\n",
        "                                         resultTuple[2], resultTuple[3], resultTuple[4], use_bias=finalBias)\n",
        "        np.savetxt(output_name, predictedY)\n",
        "        logger.log(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQxKFMeJGC3F"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHFeU92V8ZNH"
      },
      "source": [
        "## Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "8T4CjA9T8bJB"
      },
      "outputs": [],
      "source": [
        "def learn(data, logger, lambdas=None, seed=None, numDims=None, approach=None, metric=None, raw_metric=None,\n",
        "          output_name=None, propensities_desc=None):\n",
        "    clipVals = [-1]\n",
        "    #biasModes = ['Free', 'Regularized']\n",
        "    biasModes = ['Regularized']\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    numBiasModes = len(biasModes)\n",
        "    numLambdas = len(lambdas)\n",
        "    numDimSettings = len(numDims)\n",
        "    numClipSettings = len(clipVals)\n",
        "    numParamSettings = numLambdas * numDimSettings * numClipSettings * numBiasModes\n",
        "\n",
        "    paramSettings = list(itertools.product(lambdas, numDims, clipVals, biasModes))\n",
        "    numApproaches = 1\n",
        "\n",
        "    selfMatrix = data.train\n",
        "\n",
        "    logger.log(\"Starting learning...\")\n",
        "    logger.log(\"\\t-metric: \" + raw_metric, 2)\n",
        "    logger.log(\"\\t-lambda values: \" + str(lambdas), 2)\n",
        "    logger.log(\"\\t-dimension values: \" + str(numDims), 2)\n",
        "    logger.log(\"\\t-propensity scoring method: \" + propensities_desc)\n",
        "    if data.propensities is not None:\n",
        "        invP = np.reciprocal(data.propensities)\n",
        "        invP = np.ma.array(invP, dtype=np.longdouble, copy=False,\n",
        "                              mask=np.ma.getmask(selfMatrix), fill_value=0, hard_mask=True)\n",
        "    else:\n",
        "        invP = None\n",
        "\n",
        "    foldScores = np.zeros((numApproaches, 4, numParamSettings), dtype=float)\n",
        "\n",
        "    observationIndices = np.ma.nonzero(selfMatrix)\n",
        "    numObservations = np.ma.count(selfMatrix)\n",
        "\n",
        "    shuffleIndices = np.random.permutation(numObservations)\n",
        "    fractionObservations = int(numObservations / 4)\n",
        "    firstFold = shuffleIndices[:fractionObservations]\n",
        "    secondFold = shuffleIndices[fractionObservations:2 * fractionObservations]\n",
        "    thirdFold = shuffleIndices[2 * fractionObservations:3 * fractionObservations]\n",
        "    fourthFold = shuffleIndices[3 * fractionObservations:]\n",
        "\n",
        "    logger.log(\"Split %d observations into folds. Fold sizes: %s\" %\n",
        "               (len(shuffleIndices), str([len(firstFold), len(secondFold), len(thirdFold), len(fourthFold)])),\n",
        "               2)\n",
        "\n",
        "    for fold in range(4):\n",
        "        logger.log(\"Learning on fold %d \" % fold)\n",
        "        trainObservations = np.ma.copy(selfMatrix)\n",
        "        testObservations = np.ma.copy(selfMatrix)\n",
        "\n",
        "        if fold == 0:\n",
        "            trainObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
        "                np.ma.masked\n",
        "        elif fold == 1:\n",
        "            trainObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
        "                np.ma.masked\n",
        "        elif fold == 2:\n",
        "            trainObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
        "                np.ma.masked\n",
        "        elif fold == 3:\n",
        "            trainObservations[observationIndices[0][fourthFold], observationIndices[1][fourthFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "            testObservations[observationIndices[0][firstFold], observationIndices[1][firstFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][secondFold], observationIndices[1][secondFold]] = \\\n",
        "                np.ma.masked\n",
        "            testObservations[observationIndices[0][thirdFold], observationIndices[1][thirdFold]] = \\\n",
        "                np.ma.masked\n",
        "\n",
        "        # Get starting params by SVD\n",
        "        startTuple = INIT_PARAMS(trainObservations, 40)\n",
        "        normN = \"Vanilla\"\n",
        "        approachIndex = 0\n",
        "\n",
        "        modelsPerLambda = Parallel(n_jobs=-1, verbose=0)(delayed(MF_TRAIN)(param,\n",
        "                                                                                 trainObservations, invP, normN,\n",
        "                                                                                 raw_metric, startTuple)\n",
        "                                                         for param in paramSettings)\n",
        "\n",
        "        for lambdaIndex, eachModel in enumerate(modelsPerLambda):\n",
        "            selectedBiasMode = paramSettings[lambdaIndex][3]\n",
        "            selectedBias = True\n",
        "            if selectedBiasMode == 'None':\n",
        "                selectedBias = False\n",
        "            predictedY = PREDICTED_SCORES(eachModel[0], eachModel[1],\n",
        "                                             eachModel[2], eachModel[3], eachModel[4], use_bias=selectedBias)\n",
        "\n",
        "            score = None\n",
        "            if invP is not None:\n",
        "                score = metric(testObservations, predictedY, 4.0 * invP)\n",
        "            else:\n",
        "                score = metric(testObservations, predictedY, invP)\n",
        "            score = score[0]\n",
        "            foldScores[approachIndex, fold, lambdaIndex] = score\n",
        "\n",
        "            logger.log(\"\\tLambda/NumDims: \" + str(paramSettings[lambdaIndex]) +\n",
        "                       \", Test Fold Score: \" + str(score), 2)\n",
        "\n",
        "    eventualApproachParams = []\n",
        "\n",
        "    normN = \"Vanilla\"\n",
        "    approachIndex = 0\n",
        "    approachScores = foldScores[approachIndex, :, :]\n",
        "    allFoldScores = approachScores.sum(axis=0, dtype=float)\n",
        "    bestLambdaIndex = np.argmin(allFoldScores)\n",
        "    bestLambda = paramSettings[bestLambdaIndex]\n",
        "    logger.log(\"Retraining with best hyperparameter values: \" + str(bestLambda))\n",
        "    logger.log(\"Chosen from average cross-validation performance:\", 2)\n",
        "    for everyLambdaIndex, everyLambda in enumerate(paramSettings):\n",
        "        logger.log(\"\\t\" + str(everyLambda) + \": \" +  str(allFoldScores[everyLambdaIndex]/4), 2)\n",
        "    eventualApproachParams.append((approach, invP, normN, bestLambda))\n",
        "\n",
        "    finalModels = Parallel(n_jobs=-1, verbose=0)(delayed(FINAL_TRAIN)(approachTup,\n",
        "                                                                            raw_metric, selfMatrix, startTuple)\n",
        "                                                 for approachTup in eventualApproachParams)\n",
        "\n",
        "    for approachID, approachTuple in enumerate(eventualApproachParams):\n",
        "        resultTuple = finalModels[approachID]\n",
        "        finalBiasMode = approachTuple[3][3]\n",
        "        finalBias = True\n",
        "        if finalBiasMode == 'None':\n",
        "            finalBias = False\n",
        "\n",
        "        predictedY = PREDICTED_SCORES(resultTuple[0], resultTuple[1],\n",
        "                                         resultTuple[2], resultTuple[3], resultTuple[4], use_bias=finalBias)\n",
        "        np.savetxt(output_name, predictedY)\n",
        "        logger.log(\"Done.\")\n",
        "    return predictedY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "JA-zrq2fDqJj"
      },
      "outputs": [],
      "source": [
        "class Files(object):\n",
        "    def __init__(self, train, propensities):\n",
        "        self.train = train\n",
        "        self.propensities = propensities\n",
        "class Logger(object):\n",
        "    def __init__(self, verbosity_level=1):\n",
        "        self._verbosity_level = verbosity_level\n",
        "\n",
        "    def log(self, message, level=1):\n",
        "        if level <= self._verbosity_level:\n",
        "            print(message)\n",
        "            sys.stdout.flush()\n",
        "def load_ratings(filename):\n",
        "    try:\n",
        "        raw_matrix = np.loadtxt(filename)\n",
        "        return np.ma.array(raw_matrix, dtype=int, copy=False,\n",
        "                              mask=raw_matrix <= 0, fill_value=0, hard_mask=True)\n",
        "    except:\n",
        "        print(\"Error: Could not load rating file '%s'\") % filename\n",
        "        exit()\n",
        "def load_propensities(filename):\n",
        "    try:\n",
        "        return np.loadtxt(filename)\n",
        "    except:\n",
        "        print(\"Error: Could not load propensities.\")\n",
        "        exit()\n",
        "def check_writeable(filename):\n",
        "    try:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            pass\n",
        "        os.remove(filename)\n",
        "        return True, \"\"\n",
        "    except IOError:\n",
        "        print(\"Error: Could not open file '%s' for writing\") % filename\n",
        "        exit()\n",
        "def statistic_rating(rating_matrix):\n",
        "  flatten = rating_matrix.flatten()\n",
        "  num_rating = len(flatten)\n",
        "  counter = Counter(flatten)\n",
        "  num_observed = num_rating - counter[0]\n",
        "  marginal_prob = [counter[i+1] for i in range(5)]\n",
        "  marginal_prob = [i * 1.0 / sum(marginal_prob) for i in marginal_prob]\n",
        "  return marginal_prob, num_observed/num_rating\n",
        "\n",
        "class Propensity():\n",
        "  def __init__(self, num_user, num_item) -> None:\n",
        "      self.num_user = num_user\n",
        "      self.num_item = num_item \n",
        "  def fit(self, train, partial_MCAR):\n",
        "    p_r, _ = statistic_rating(partial_MCAR)\n",
        "    p_r_observed, p_observed = statistic_rating(train)\n",
        "    self.ips = [p_r_observed[i] * p_observed / p_r[i] for i in range(5)]\n",
        "  def predict(self, test):\n",
        "    propensities = np.zeros((self.num_user, self.num_item))\n",
        "    for i in range(self.num_user):\n",
        "      for j in range(self.num_item):\n",
        "        rating = test[i,j]\n",
        "        if rating != 0:\n",
        "          propensities[i,j] = self.ips[rating-1]\n",
        "        else:\n",
        "          propensities[i,j] = 1/(self.num_user)\n",
        "    return propensities\n",
        "def generate_column_name(name, size, add_id=True):\n",
        "  result = []\n",
        "  if add_id: \n",
        "    result.append(name + \"_id\")\n",
        "  for i in range(size):\n",
        "    result.append(name + \"_\" + str(i))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCQRXXDzEHIH"
      },
      "source": [
        "## Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fNB0Ni1QEGx7"
      },
      "outputs": [],
      "source": [
        "lambdas = [0.08, 25]\n",
        "numDims = [10]\n",
        "clipVals = [-1]\n",
        "verbosity = 2\n",
        "seed = 387\n",
        "completed = 'completed_ratings.ascii'\n",
        "\n",
        "my_logger = Logger(verbosity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjdnbyISZXFc"
      },
      "source": [
        "## Experiment 1\n",
        "Th nghim v kh nng nh gi ca IPS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML100K Observation Model."
      ],
      "metadata": {
        "id": "lJuI1666OVFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hun luyn"
      ],
      "metadata": {
        "id": "mi8bsH-VONmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "l6nXd21COB-L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "so8FItvUyixK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "7d8d4984-b0d0-479f-c0d5-4bdc630f2f03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "itemId  1     2     3     4     5     6     7     8     9     10    ...  1673  \\\n",
              "userId                                                              ...         \n",
              "1        5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   0.0   \n",
              "2        4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   0.0   \n",
              "3        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "4        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "5        4.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "\n",
              "itemId  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
              "userId                                                        \n",
              "1        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "2        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "3        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "4        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "5        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "\n",
              "[5 rows x 1682 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdeec8c2-1893-4db4-95a6-6411ddfa4714\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>itemId</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "      <th>1682</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  1682 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdeec8c2-1893-4db4-95a6-6411ddfa4714')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdeec8c2-1893-4db4-95a6-6411ddfa4714 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdeec8c2-1893-4db4-95a6-6411ddfa4714');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "ratings_df = pd.read_csv('/content/drive/My Drive/Thesis/data/ML100K//ml-100k/u.data', \n",
        "                      delimiter= '\\t', \n",
        "                      names=[\"userId\", \"itemId\", \"rating\", 'timestamp'])\n",
        "R_df = ratings_df.pivot(index = 'userId', columns ='itemId', values = 'rating').fillna(0)\n",
        "R_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAFygfMZDsrL"
      },
      "source": [
        "Chun b d liu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "TN0Y6uKussS8"
      },
      "outputs": [],
      "source": [
        "movielen_df = ratings_df[['userId', 'itemId', 'rating']]\n",
        "movielen = movielen_df.pivot(index = 'userId', columns ='itemId', values = 'rating').fillna(0)\n",
        "movielen = np.ma.array(movielen, dtype=int, copy=False,\n",
        "                              mask=movielen <= 0, fill_value=0, hard_mask=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn"
      ],
      "metadata": {
        "id": "-vuABe06bQXm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "odLXnoSt7bdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dfd3e00-ea60-45e9-966c-415950c1e6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [10]\n",
            "\t-dimension values: [20]\n",
            "\t-propensity scoring method: naive (uniform)\n",
            "Split 100000 observations into folds. Fold sizes: [25000, 25000, 25000, 25000]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.8473644963973472097\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.8340936934328850373\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.83814545211668033977\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.8424150203048410107\n",
            "Retraining with best hyperparameter values: (10, 20, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(10, 20, -1, 'Regularized'): 0.8405046655629385\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "lambdas = [10]\n",
        "numDims = [20]\n",
        "\n",
        "propensities = None\n",
        "propensities_desc = \"naive (uniform)\"\n",
        "data = Files(movielen, propensities)\n",
        "\n",
        "metric = MSE\n",
        "raw_metric = 'MSE'\n",
        "\n",
        "completed_rating = learn(data, my_logger, lambdas=lambdas, numDims=numDims, metric=metric, approach=\"IPS\",\n",
        "          seed=seed, raw_metric='MSE', output_name = completed, propensities_desc=propensities_desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "MNUsgjLH5Fni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1059b25f-a7d6-456c-f08f-1a9da562ed43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phn phi d liu ca cc rating trong tp ML completed:\n",
            "1.0    0.001\n",
            "2.0    0.027\n",
            "3.0    0.601\n",
            "4.0    0.364\n",
            "5.0    0.007\n",
            "Name: rating, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "ml100k_completed = completed_rating.copy()\n",
        "ml100k_completed = ml100k_completed.round()\n",
        "completed_df = pd.DataFrame(ml100k_completed).stack().reset_index()\n",
        "completed_df.columns = ['userId', 'itemId', 'rating']\n",
        "\n",
        "completed_df.loc[completed_df['rating'] == 6, 'rating'] = 5\n",
        "completed_df.loc[completed_df['rating'] == 0, 'rating'] = 1\n",
        "\n",
        "count = completed_df['rating'].value_counts().sort_index()\n",
        "print('Phn phi d liu ca cc rating trong tp ML completed:')\n",
        "print((count/sum(count)).round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHyxHyV7vFTw"
      },
      "source": [
        "#### iu chnh rating\n",
        "S lng im d liu 3 v 4 rt chnh lch so vi im d liu 1,2 v 5. V vy cn ty chnh li sao cho tun theo phn phi:\n",
        "\n",
        "<!-- **[0.06, 0.11, 0.27, 0.35, 0.21]** -->\n",
        "**[0.526, 0.242, 0.144, 0.062, 0.026]** ca tp Yahoo do ngi dng la chn ngu nhin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW6UN9crzUg4"
      },
      "source": [
        "Quantile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_yahoo_df = pd.read_csv('/content/drive/My Drive/Thesis/data/R3/ydata-ymusic-rating-study-v1_0-test.txt', delimiter='\\t', names=[\"user_id\", \"item_id\", \"rating\"])\n",
        "count = test_yahoo_df['rating'].value_counts()\n",
        "# distributed_yahoo = (count/sum(count)).round(2)\n",
        "distributed_yahoo = (count/sum(count))\n",
        "distributed_yahoo.round(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_qOiJgsMt-W",
        "outputId": "114839ca-6935-4d77-a28f-bef53ca7b328"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.526\n",
              "2    0.242\n",
              "3    0.144\n",
              "4    0.062\n",
              "5    0.026\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "QeFCWmh0wYgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9682054a-2633-46de-f076-ce955a6805e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.526241    3.393385\n",
              "0.768167    3.669438\n",
              "0.912056    3.960339\n",
              "0.974481    4.248344\n",
              "1.000000    6.092850\n",
              "Name: rating, dtype: float128"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "p = distributed_yahoo.values\n",
        "p[1] = p[0] + p[1]\n",
        "p[2] = p[2] + p[1]\n",
        "p[3] = p[3] + p[2]\n",
        "p[4] = p[4] + p[3]\n",
        "\n",
        "movie = completed_rating.copy()\n",
        "movie = pd.DataFrame(movie).stack().reset_index()\n",
        "movie.columns = ['userId', 'itemId', 'rating']\n",
        "\n",
        "quantile = movie['rating'].quantile(p)\n",
        "quantile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdHgcaDAzofp"
      },
      "source": [
        "Cp nht rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "UZeqTpalxTwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89521600-8be2-45a0-8250-fbd693507052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phn phi d liu ca cc rating trong tp ML completed sau khi iu chnh:\n",
            "1.0    0.526241\n",
            "2.0    0.241926\n",
            "3.0    0.143889\n",
            "4.0    0.062426\n",
            "5.0    0.025519\n",
            "Name: rating, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Get index\n",
        "index5 = movie[movie['rating'] >= quantile[quantile.index[3]]].index\n",
        "index4 = movie[(movie['rating'] >= quantile[quantile.index[2]]) & (movie['rating'] < quantile[quantile.index[3]])].index\n",
        "index3 = movie[(movie['rating'] >= quantile[quantile.index[1]]) & (movie['rating'] < quantile[quantile.index[2]])].index\n",
        "index2 = movie[(movie['rating'] >= quantile[quantile.index[0]]) & (movie['rating'] < quantile[quantile.index[1]])].index\n",
        "index1 = movie[movie['rating'] < quantile[quantile.index[0]]].index\n",
        "\n",
        "# Update index\n",
        "movie.loc[index5, 'rating'] = 5\n",
        "movie.loc[index4, 'rating'] = 4\n",
        "movie.loc[index3, 'rating'] = 3\n",
        "movie.loc[index2, 'rating'] = 2\n",
        "movie.loc[index1, 'rating'] = 1\n",
        "\n",
        "count = movie['rating'].value_counts().sort_index()\n",
        "print('Phn phi d liu ca cc rating trong tp ML completed sau khi iu chnh:')\n",
        "print(count/sum(count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zu7EXwn5fAm"
      },
      "source": [
        "### Th nghim vi s mu d liu MCAR khc nhau"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hm tm k"
      ],
      "metadata": {
        "id": "YyIDQMAqOq36"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "qEcSQ_XHuhzd"
      },
      "outputs": [],
      "source": [
        "def find_k(alpha,count):\n",
        "  k = (5*(1683*944)/100) / (pow(alpha,3)*count[1] + pow(alpha,2)*count[2] + \n",
        "                            alpha*count[3] + count[4] + count[5])\n",
        "  return k\n",
        "\n",
        "def find_propensity(alpha, count):\n",
        "  k = find_k(alpha, count)\n",
        "  print('k: ', k)\n",
        "  print('alpha: ', alpha)\n",
        "  p = count.copy().astype(float)\n",
        "  p[1] = pow(alpha,3)*k\n",
        "  p[2] = pow(alpha,2)*k\n",
        "  p[3] = alpha*k\n",
        "  p[4] = k\n",
        "  p[5] = k\n",
        "  return p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX3tXAT1EQ59"
      },
      "source": [
        "Tnh k cho tng rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "OCYIrxzR-CQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610b2b61-ba5a-478b-97cb-c7b7fbe91058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k:  0.3400986204482767\n",
            "alpha:  0.25\n",
            "Phan phoi cua du lieu quan sat duoc:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    0.06\n",
              "2.0    0.10\n",
              "3.0    0.24\n",
              "4.0    0.42\n",
              "5.0    0.17\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "propensity_movie = find_propensity(0.25, count)\n",
        "a = count*propensity_movie\n",
        "print('Phan phoi cua du lieu quan sat duoc:')\n",
        "(a/a.sum()).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8GLAchnE_aA"
      },
      "source": [
        "#### Chun b d liu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Train"
      ],
      "metadata": {
        "id": "6dbQ2tkweoUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "DTL5XLs0HfDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca86a1e5-3787-438a-9da9-b3e9542cdb1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1506687\n",
              "4      33675\n",
              "3      19405\n",
              "5      13766\n",
              "2       8157\n",
              "1       4436\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# S lng rating cn ly trong tp quan st c\n",
        "number_ratings = (count*propensity_movie).round().astype('int')\n",
        "# Create full 0 matrix\n",
        "observed_rating = movie.copy()\n",
        "observed_rating.loc[:, 'rating'] = 0\n",
        "# Assign value in observed_rating\n",
        "for i in range(1,6):\n",
        "  rating_i = movie[movie['rating']==i]\n",
        "  sample_i = rating_i.sample(n=number_ratings[i])\n",
        "  observed_rating.loc[sample_i.index, 'rating'] = i\n",
        "observed_rating['rating'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Test"
      ],
      "metadata": {
        "id": "eMO5yWqReHQJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "uj3ta3725VFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "50a3f1e2-1ae2-4710-c135-91fb782d9b1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  itemId  rating\n",
              "0       0       0     0.0\n",
              "1       0       1     1.0\n",
              "2       0       2     1.0\n",
              "3       0       3     2.0\n",
              "4       0       4     1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af876265-8820-4f1b-a631-7b2c165938ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>itemId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af876265-8820-4f1b-a631-7b2c165938ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af876265-8820-4f1b-a631-7b2c165938ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af876265-8820-4f1b-a631-7b2c165938ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# Ly index ca nhng gi tr  c chn v trong ma trn quan st c\n",
        "observed_index = observed_rating[observed_rating['rating'] > 0].index\n",
        "# To ma trn cha nhng gi tr cn li dng trong test\n",
        "remain_rating = movie.copy()\n",
        "remain_rating.loc[observed_index, 'rating'] = 0\n",
        "remain_rating.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1LoA0J7KqHJ"
      },
      "source": [
        "#### MF - Naive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "BEcx4AmNFX-u"
      },
      "outputs": [],
      "source": [
        "# Chuyn ma trn quan st c v dng numpy.ma\n",
        "observed_rating_df = observed_rating.pivot(index = 'userId', columns ='itemId', values = 'rating')\n",
        "observed_movielen = np.ma.array(observed_rating_df, dtype=int, copy=False,\n",
        "                              mask=observed_rating_df <= 0, fill_value=0, hard_mask=True)\n",
        "# Chuyn ma trn cn li v dng numpy.ma\n",
        "remain_rating_df = remain_rating.pivot(index = 'userId', columns ='itemId', values = 'rating')\n",
        "remain_movielen = np.ma.array(remain_rating_df, dtype=int, copy=False,\n",
        "                              mask=remain_rating_df <= 0, fill_value=0, hard_mask=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKCeiEklPop_"
      },
      "source": [
        "##### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "gID7syzsKJxm"
      },
      "outputs": [],
      "source": [
        "lambdas = [1, 10, 25]\n",
        "numDims = [10, 20]\n",
        "\n",
        "propensities = None\n",
        "propensities_desc = \"naive (uniform)\"\n",
        "data = Files(observed_movielen, propensities)\n",
        "\n",
        "metric = MSE\n",
        "raw_metric = 'MSE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "TzHlmXZyKJxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1482484-55f3-4e83-ef03-8ce0129df663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: naive (uniform)\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.1418165243329074347\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.16317163532315063617\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3180638695719351159\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22636458860496606136\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.47219296978888095247\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.35524784135992011096\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13527722107717069304\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.15991073876053481519\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3134493214534864929\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.2209800180640507837\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.4683869259654275995\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.35086004007272245645\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13828753904819107015\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.16612208926098469646\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.31812124243359133854\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22483821491774456837\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.47449818530845815027\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.355850702604000099\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13525042599481351295\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.16080596352374094149\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.31312107804171907416\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22254990071547878684\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.46306987694852944114\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.34934002198013342682\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.13765792761327067\n",
            "\t(1, 20, -1, 'Regularized'): 0.16250260671710276\n",
            "\t(10, 10, -1, 'Regularized'): 0.315688877875183\n",
            "\t(10, 20, -1, 'Regularized'): 0.22368318057556005\n",
            "\t(25, 10, -1, 'Regularized'): 0.4695369895028241\n",
            "\t(25, 20, -1, 'Regularized'): 0.35282465150419406\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "completed_rating_naive = learn(data, my_logger, lambdas=lambdas, numDims=numDims, metric=metric, approach=\"IPS\",\n",
        "          seed=seed, raw_metric='MSE', output_name = completed, propensities_desc=propensities_desc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVuQPNJP6n4N"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "lzOXJdxc6oFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56024c88-ad27-4383-f998-dee08efc33cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.2496634647176678176\n",
            "MAE: 0.38237104487222396167\n"
          ]
        }
      ],
      "source": [
        "for metric in ['MSE', 'MAE']:\n",
        "  if metric == 'MSE':\n",
        "    metricValue = MSE(remain_movielen, completed_rating_naive, None)[0]\n",
        "  else:\n",
        "    metricValue = MAE(remain_movielen, completed_rating_naive, None)[0]\n",
        "  print(metric + ': ' + str(metricValue))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug-xujjwK2gn"
      },
      "source": [
        "#### MF - IPS vi IPS bit trc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkLi-grbLkmK"
      },
      "source": [
        "##### Propensity matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "bSOOsyIoNL4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "e0d1a634-5fa5-4294-cd86-9afa9cca180f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "itemId      0         1         2         3         4         5         6     \\\n",
              "userId                                                                         \n",
              "0       0.340099  0.005314  0.005314  0.021256  0.005314  0.085025  0.340099   \n",
              "1       0.085025  0.005314  0.005314  0.021256  0.021256  0.085025  0.085025   \n",
              "2       0.005314  0.005314  0.005314  0.005314  0.005314  0.005314  0.005314   \n",
              "3       0.340099  0.085025  0.085025  0.085025  0.085025  0.340099  0.340099   \n",
              "4       0.085025  0.005314  0.005314  0.005314  0.005314  0.005314  0.340099   \n",
              "\n",
              "itemId      7         8         9     ...      1672      1673      1674  \\\n",
              "userId                                ...                                 \n",
              "0       0.085025  0.340099  0.021256  ...  0.005314  0.005314  0.005314   \n",
              "1       0.340099  0.340099  0.085025  ...  0.021256  0.021256  0.021256   \n",
              "2       0.021256  0.021256  0.021256  ...  0.005314  0.005314  0.005314   \n",
              "3       0.340099  0.340099  0.340099  ...  0.085025  0.085025  0.085025   \n",
              "4       0.021256  0.005314  0.005314  ...  0.005314  0.005314  0.005314   \n",
              "\n",
              "itemId      1675      1676      1677      1678      1679      1680      1681  \n",
              "userId                                                                        \n",
              "0       0.005314  0.005314  0.005314  0.005314  0.005314  0.005314  0.005314  \n",
              "1       0.005314  0.021256  0.005314  0.021256  0.005314  0.021256  0.021256  \n",
              "2       0.005314  0.005314  0.005314  0.005314  0.005314  0.005314  0.005314  \n",
              "3       0.085025  0.085025  0.085025  0.085025  0.085025  0.085025  0.085025  \n",
              "4       0.005314  0.005314  0.005314  0.005314  0.005314  0.005314  0.005314  \n",
              "\n",
              "[5 rows x 1682 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbd1a1e6-9fec-4ab3-989c-2ba5e8fae709\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>itemId</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1672</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.021256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.085025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.085025</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.340099</td>\n",
              "      <td>0.021256</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "      <td>0.005314</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  1682 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbd1a1e6-9fec-4ab3-989c-2ba5e8fae709')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbd1a1e6-9fec-4ab3-989c-2ba5e8fae709 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbd1a1e6-9fec-4ab3-989c-2ba5e8fae709');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# Assign propensity to movie matrix\n",
        "propensity_movie_df = movie.copy()\n",
        "propensity_movie_df = propensity_movie_df.rename(columns = {'rating':'propensity'})\n",
        "for i in range(1,6):\n",
        "  propensity_movie_df.loc[propensity_movie_df['propensity'] == i, 'propensity'] = propensity_movie[i]\n",
        "\n",
        "# create propensity for training\n",
        "propensity_movie_df = propensity_movie_df.pivot(index = 'userId', columns ='itemId', values = 'propensity')\n",
        "propensity_movie_df.head()      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBirGsPPrLW"
      },
      "source": [
        "##### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "vsT_d5Z3OVgt"
      },
      "outputs": [],
      "source": [
        "lambdas = [1, 10, 25]\n",
        "numDims = [10, 20]\n",
        "\n",
        "propensities = propensity_movie_df\n",
        "propensities_desc = \"IPS\"\n",
        "data = Files(observed_movielen, propensities)\n",
        "\n",
        "metric = MSE\n",
        "raw_metric = 'MSE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "pW9cbaXiOVgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d37c74b-682c-4076-f231-8b375a22982f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17975108430167524213\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19254513163462155514\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33690622722091666754\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24179965571645012284\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.49875830379030488938\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3751618383892722548\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18485740712508932057\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19883727852963525506\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33907068405141086625\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24502198207074898016\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.49834645175465274396\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3754875320251231221\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18592873448476110825\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19981774533288876855\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33892715233325312153\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24372961541277297799\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5018050265194532697\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37689508450085791496\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.16368630361102563819\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.1791322658577999936\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32314056887117306445\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22673480982911724553\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.4853665441394307611\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3610307904420826189\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.17855588238063783\n",
            "\t(1, 20, -1, 'Regularized'): 0.19258310533873638\n",
            "\t(10, 10, -1, 'Regularized'): 0.3345111581191884\n",
            "\t(10, 20, -1, 'Regularized'): 0.23932151575727234\n",
            "\t(25, 10, -1, 'Regularized'): 0.4960690815509604\n",
            "\t(25, 20, -1, 'Regularized'): 0.372143811339334\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "completed_rating_ips = learn(data, my_logger, lambdas=lambdas, numDims=numDims, metric=metric, approach=\"IPS\",\n",
        "          seed=seed, raw_metric='MSE', output_name = completed, propensities_desc=propensities_desc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-Ij3A70x-pI"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Q0y8et862A0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e777d09-75cb-454d-b7ed-472f9b70001c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.15022906243016289214\n",
            "MAE: 0.28615342032836335338\n"
          ]
        }
      ],
      "source": [
        "for metric in ['MSE', 'MAE']:\n",
        "  if metric == 'MSE':\n",
        "    metricValue = MSE(remain_movielen, completed_rating_ips, None)[0]\n",
        "  else:\n",
        "    metricValue = MAE(remain_movielen, completed_rating_ips, None)[0]\n",
        "  print(metric + ': ' + str(metricValue))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRwCzEr4WMuM"
      },
      "source": [
        "#### IPS vi IPS c tm thng qua NB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7TfUpgVWRZf"
      },
      "source": [
        "##### Propensity thng qua NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "WPIBJfaIWQdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68345de-3d3e-45b5-fe33-653d954e9a4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79306"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "percent = 0.05\n",
        "number_ratings_nb = int(0.05 * movielen.shape[0] * movielen.shape[1])\n",
        "number_ratings_nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "DjgjV0scd7G8"
      },
      "outputs": [],
      "source": [
        "MCAR_sample_df = movie.copy()\n",
        "MCAR_sample_df.loc[:, 'rating'] = 0\n",
        "random_sample = movie.sample(n=number_ratings_nb)\n",
        "MCAR_sample_df = pd.concat([MCAR_sample_df[['userId', 'itemId']], random_sample['rating']], axis = 1).fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "HdGka6YOoutV"
      },
      "outputs": [],
      "source": [
        "# Chuyn ma trn quan st c v dng numpy.ma\n",
        "MCAR_sample = MCAR_sample_df.pivot(index = 'userId', columns ='itemId', values = 'rating')\n",
        "MCAR_sample = np.ma.array(MCAR_sample, dtype=int, copy=False,\n",
        "                              mask=MCAR_sample <= 0, fill_value=0, hard_mask=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Io-EGoYgWQRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9654ef2-661a-4981-867c-18dc387ad6c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33341458, 0.00106045, 0.00106045, ..., 0.00106045, 0.00106045,\n",
              "        0.00106045],\n",
              "       [0.00106045, 0.00106045, 0.00106045, ..., 0.00106045, 0.00106045,\n",
              "        0.00106045],\n",
              "       [0.00106045, 0.00106045, 0.00106045, ..., 0.00106045, 0.00106045,\n",
              "        0.00106045],\n",
              "       ...,\n",
              "       [0.00106045, 0.00106045, 0.00106045, ..., 0.00106045, 0.00106045,\n",
              "        0.00106045],\n",
              "       [0.00106045, 0.00106045, 0.00106045, ..., 0.00106045, 0.00106045,\n",
              "        0.00106045],\n",
              "       [0.00106045, 0.00106045, 0.00106045, ..., 0.00106045, 0.00106045,\n",
              "        0.00106045]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "p = Propensity(observed_movielen.shape[0], observed_movielen.shape[1])\n",
        "p.fit(observed_movielen.data, MCAR_sample.data)\n",
        "propensity_movielen = p.predict(observed_movielen.data)\n",
        "propensity_movielen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrtKGrVg4Qro"
      },
      "source": [
        "##### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "Gees-W5S4Ku8"
      },
      "outputs": [],
      "source": [
        "lambdas = [1, 10, 25]\n",
        "numDims = [10, 20]\n",
        "\n",
        "propensities = propensity_movielen\n",
        "propensities_desc = \"IPS\"\n",
        "data = Files(observed_movielen, propensities)\n",
        "\n",
        "metric = MSE\n",
        "raw_metric = 'MSE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "75eTVHIu4Ksv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1871cd67-10f2-4e1f-9ecc-ac435866f492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17596676453188889796\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19150508016844903972\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33753950774443161037\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24127645711859375618\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.49978568142210016837\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37581723161149575453\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18494197990584404287\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19810544637298219708\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33901738814068563743\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24473062694450635047\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.49950148532149862046\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37619151985573429044\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18347752666664739374\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.20011296610524308466\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33904754334661592316\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24338793723360829723\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5031155742003175177\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37661898005620939213\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.16561638608952095011\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.17935532403049471504\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32302991146503227948\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22662342988328470345\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.48636539045783149475\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.36119254650136849383\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.17750066429847533\n",
            "\t(1, 20, -1, 'Regularized'): 0.19226970416929226\n",
            "\t(10, 10, -1, 'Regularized'): 0.3346585876741914\n",
            "\t(10, 20, -1, 'Regularized'): 0.2390046127949983\n",
            "\t(25, 10, -1, 'Regularized'): 0.49719203285043695\n",
            "\t(25, 20, -1, 'Regularized'): 0.372455069506202\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "completed_rating_ips_nb = learn(data, my_logger, lambdas=lambdas, numDims=numDims, metric=metric, approach=\"IPS\",\n",
        "          seed=seed, raw_metric='MSE', output_name = completed, propensities_desc=propensities_desc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7Lb0cz44J-p"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "g-_BcqDv4Km3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c539f854-498f-4f3c-918a-0b58d20f9b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.15021282072044328344\n",
            "MAE: 0.2861413367715269414\n"
          ]
        }
      ],
      "source": [
        "for metric in ['MSE', 'MAE']:\n",
        "  if metric == 'MSE':\n",
        "    metricValue = MSE(remain_movielen, completed_rating_ips_nb, None)[0]\n",
        "  else:\n",
        "    metricValue = MAE(remain_movielen, completed_rating_ips_nb, None)[0]\n",
        "  print(metric + ': ' + str(metricValue))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfUNqmkT7T_4"
      },
      "source": [
        "#### Th vi nhiu s lng d liu MCAR khc nhau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD1jaDsS9Ov_"
      },
      "source": [
        "##### Hm hun luyn trn s lng MCAR khc nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "-bL8LJWs7gvB"
      },
      "outputs": [],
      "source": [
        "def train_with_number_MCAR(number_ratings_nb):\n",
        "  # Khi to ma trn MCAR_sample vi cc mu c ly ngu nhin t tp movie full\n",
        "  MCAR_sample_df = movie.copy()\n",
        "  MCAR_sample_df.loc[:, 'rating'] = 0\n",
        "  random_sample = movie.sample(n=number_ratings_nb)\n",
        "  MCAR_sample_df = pd.concat([MCAR_sample_df[['userId', 'itemId']], random_sample['rating']], axis = 1).fillna(0)\n",
        "\n",
        "  # Chuyn ma trn quan st c v dng numpy.ma\n",
        "  MCAR_sample = MCAR_sample_df.pivot(index = 'userId', columns ='itemId', values = 'rating')\n",
        "  MCAR_sample = np.ma.array(MCAR_sample, dtype=int, copy=False,\n",
        "                                mask=MCAR_sample <= 0, fill_value=0, hard_mask=True)\n",
        "\n",
        "  # Tnh propensity\n",
        "  p = Propensity(observed_movielen.shape[0], observed_movielen.shape[1])\n",
        "  p.fit(observed_movielen.data, MCAR_sample.data)\n",
        "  propensity_movielen = p.predict(observed_movielen.data)\n",
        "  propensity_movielen\n",
        "\n",
        "  # Khi to gi tr tr v\n",
        "  result_MSE = []\n",
        "  result_MAE = []\n",
        "\n",
        "  # Khi to cc tham s\n",
        "  lambdas = [1, 10, 25]\n",
        "  numDims = [10, 20]\n",
        "  propensities = propensity_movielen\n",
        "  propensities_desc = \"IPS\"\n",
        "  data = Files(observed_movielen, propensities)\n",
        "  metric = MSE\n",
        "  raw_metric = 'MSE'\n",
        "\n",
        "  # Training\n",
        "  completed_rating_ips_nb = learn(data, my_logger, lambdas=lambdas, numDims=numDims, metric=metric, approach=\"IPS\",\n",
        "            seed=seed, raw_metric='MSE', output_name = completed, propensities_desc=propensities_desc)\n",
        "  # Test\n",
        "  for metric in ['MSE', 'MAE']:\n",
        "    if metric == 'MSE':\n",
        "      metricValue = MSE(remain_movielen, completed_rating_ips_nb, None)[0]\n",
        "      result_MSE.append(metricValue)\n",
        "    else:\n",
        "      metricValue = MAE(remain_movielen, completed_rating_ips_nb, None)[0]\n",
        "      result_MAE.append(metricValue)\n",
        "  return result_MSE, result_MAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePc2C92Z9azp"
      },
      "source": [
        "##### Train vi s lng MCAR khc nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "frdnimqi9Z3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020bf908-e4e9-4e9d-dc02-cf64382cfbaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17587242742832167854\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.18930126889522807289\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.34628894296978016978\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.23947343473178867571\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.53244243922035877067\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3878020872787639249\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18095246812836182297\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19356683875654343713\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3416675591960268427\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.23918948216023672711\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.52332312888399704754\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.38255330971024857986\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18077190685998561466\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19205503522452227487\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3470842127854794638\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24116902844906117722\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5348894768061720053\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3893180942422878827\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.16822494439958616821\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.17544362730055519854\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33012925169409129282\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22643222074299795501\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.51207634840989257457\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3716909184248002347\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.1764554367040638\n",
            "\t(1, 20, -1, 'Regularized'): 0.18759169254421224\n",
            "\t(10, 10, -1, 'Regularized'): 0.3412924916613444\n",
            "\t(10, 20, -1, 'Regularized'): 0.23656604152102115\n",
            "\t(25, 10, -1, 'Regularized'): 0.525682848330105\n",
            "\t(25, 20, -1, 'Regularized'): 0.38284110241402514\n",
            "Done.\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17346634789453619579\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.18596141719121122901\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33757798788336006122\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.23668647863895405056\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5144144895724207225\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37710483519613855757\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18123217503206827014\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.18962599331046397896\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3354079540942042536\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.23799574951833731201\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.50938829460159979916\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37499746049448552952\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17482657995537954488\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19072878215351741012\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33704015995260377158\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.23834118209644454706\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5173263058250422807\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.379007995838118495\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.16252924384770848239\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.17436457434998482344\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32207217475168096205\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22377804525393580091\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.49783318348648166764\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.36190859104598270378\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.17301358668242312\n",
            "\t(1, 20, -1, 'Regularized'): 0.18517019175129434\n",
            "\t(10, 10, -1, 'Regularized'): 0.3330245691704623\n",
            "\t(10, 20, -1, 'Regularized'): 0.23420036387691795\n",
            "\t(25, 10, -1, 'Regularized'): 0.5097405683713861\n",
            "\t(25, 20, -1, 'Regularized'): 0.3732547206436813\n",
            "Done.\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17963202739621802199\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19289717075632869754\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3412964106972976385\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24225027741073483784\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5076085958889654899\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.38032668008082356437\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18640504054224524982\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.20021473371168113417\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.34235600793239725088\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24529904601948694208\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5073066155990761208\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.38067207180074945111\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18633937197175488492\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.21063592021377976852\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3427770084605972193\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24448643436630670346\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5118377538883073707\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37948119475810468333\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.16524661351840056875\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.18008579224366127226\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32601799753718097483\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22700396363040049493\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.4938816119847102318\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.36527533796898194312\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.17940576335715466\n",
            "\t(1, 20, -1, 'Regularized'): 0.1959584042313627\n",
            "\t(10, 10, -1, 'Regularized'): 0.33811185615686823\n",
            "\t(10, 20, -1, 'Regularized'): 0.23975993035673226\n",
            "\t(25, 10, -1, 'Regularized'): 0.5051586443402647\n",
            "\t(25, 20, -1, 'Regularized'): 0.3764388211521649\n",
            "Done.\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17896486696688179488\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19235836229715331233\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.33835244199114182295\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24152350766932317356\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.50254055679916888934\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3771984126623393855\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18586228272321609272\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19978372122557070706\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.34019735031254396069\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.2450367800444247865\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5023045502062451099\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37738093014655015915\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.1838880841510417383\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.19971794964124749154\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3396417839903757655\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24388527117697309542\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5057067002998980707\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3767958935980918678\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.16322060947249763753\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.17992523155599484792\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3239361399801096365\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22667193163390369003\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.4888316961698927445\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.36278689045692690302\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.1779839608284093\n",
            "\t(1, 20, -1, 'Regularized'): 0.19294631617999158\n",
            "\t(10, 10, -1, 'Regularized'): 0.3355319290685428\n",
            "\t(10, 20, -1, 'Regularized'): 0.23927937263115617\n",
            "\t(25, 10, -1, 'Regularized'): 0.49984587586880114\n",
            "\t(25, 20, -1, 'Regularized'): 0.37354053171597706\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "numbers_MCAR = [50, 100, 1000, 10000]\n",
        "MSE_NB = []\n",
        "MAE_NB = []\n",
        "for number_MCAR in numbers_MCAR:\n",
        "  result_MSE, result_MAE = train_with_number_MCAR(int(number_MCAR))\n",
        "  MSE_NB.append(result_MSE)\n",
        "  MAE_NB.append(result_MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "gIHr9ZumMcsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f95c2e-2596-4690-c98b-10c905b38679"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0.1563980938586336838],\n",
              "  [0.15314243201810885724],\n",
              "  [0.15070421073209157797],\n",
              "  [0.15012244999021094018]],\n",
              " [[0.29193702702309410715],\n",
              "  [0.28919214165860494036],\n",
              "  [0.28730590843824332518],\n",
              "  [0.28584949220283676914]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "MSE_NB, MAE_NB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNfecoohBbXj"
      },
      "source": [
        "### Th nghim trn nhiu alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttdbOXsLyLab"
      },
      "source": [
        "##### Hm hun luyn trn nhiu alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "UQ39u_102AnX"
      },
      "outputs": [],
      "source": [
        "def train_with_alpha(alpha):\n",
        "  # Tm k\n",
        "  propensity_movie = find_propensity(alpha, count)\n",
        "  a = count*propensity_movie\n",
        "\n",
        "  # To b d liu train v test\n",
        "  number_ratings = (count*propensity_movie).round().astype('int')\n",
        "  observed_rating = movie.copy()\n",
        "  observed_rating.loc[:, 'rating'] = 0\n",
        "  # Assign value in observed_rating\n",
        "  for i in range(1,6):\n",
        "    rating_i = movie[movie['rating']==i]\n",
        "    sample_i = rating_i.sample(n=number_ratings[i])\n",
        "    observed_rating.loc[sample_i.index, 'rating'] = i\n",
        "  # Ly index ca nhng gi tr  c chn v trong ma trn quan st c\n",
        "  observed_index = observed_rating[observed_rating['rating'] > 0].index\n",
        "  # To ma trn cha nhng gi tr cn li dng trong test\n",
        "  remain_rating = movie.copy()\n",
        "  remain_rating.loc[observed_index, 'rating'] = 0\n",
        "\n",
        "  # Chuyn ha d liu train v test v dng numpy.ma\n",
        "  # Chuyn ma trn quan st c v dng numpy.ma\n",
        "  observed_rating_df = observed_rating.pivot(index = 'userId', columns ='itemId', values = 'rating')\n",
        "  observed_movielen = np.ma.array(observed_rating_df, dtype=int, copy=False,\n",
        "                                mask=observed_rating_df <= 0, fill_value=0, hard_mask=True)\n",
        "  # Chuyn ma trn cn li v dng numpy.ma\n",
        "  remain_rating_df = remain_rating.pivot(index = 'userId', columns ='itemId', values = 'rating')\n",
        "  remain_movielen = np.ma.array(remain_rating_df, dtype=int, copy=False,\n",
        "                                mask=remain_rating_df <= 0, fill_value=0, hard_mask=True)\n",
        "  \n",
        "  # To ma trn propensity\n",
        "  # Assign propensity to movie matrix\n",
        "  propensity_movie_df = movie.copy()\n",
        "  propensity_movie_df = propensity_movie_df.rename(columns = {'rating':'propensity'})\n",
        "  for i in range(1,6):\n",
        "    propensity_movie_df.loc[propensity_movie_df['propensity'] == i, 'propensity'] = propensity_movie[i]\n",
        "  # create propensity for training\n",
        "  propensity_movie_df = propensity_movie_df.pivot(index = 'userId', columns ='itemId', values = 'propensity')\n",
        "  propensity_movie_df.head()      \n",
        "\n",
        "\n",
        "  # Khi to gi tr tr v\n",
        "  result_MSE = []\n",
        "  result_MAE = []\n",
        "\n",
        "  # Train m hnh MF-Naive\n",
        "  print(\"*****Trainning MF-Naive*****\")\n",
        "  # Khi to cc tham s\n",
        "  lambdas = [1, 10, 25]\n",
        "  numDims = [10, 20]\n",
        "  propensities = None\n",
        "  propensities_desc = \"naive (uniform)\"\n",
        "  data = Files(observed_movielen, propensities)\n",
        "  metric = MSE\n",
        "  raw_metric = 'MSE'\n",
        "  # Train m hnh\n",
        "  completed_rating_naive = learn(data, my_logger, lambdas=lambdas, numDims=numDims, metric=metric, approach=\"IPS\",\n",
        "          seed=seed, raw_metric='MSE', output_name = completed, propensities_desc=propensities_desc)\n",
        "  \n",
        "  # Test m hnh MF-Naive\n",
        "  for metric in ['MSE', 'MAE']:\n",
        "    if metric == 'MSE':\n",
        "      metricValue = MSE(remain_movielen, completed_rating_naive, None)[0]\n",
        "      result_MSE.append(metricValue)\n",
        "    else:\n",
        "      metricValue = MAE(remain_movielen, completed_rating_naive, None)[0]\n",
        "      result_MAE.append(metricValue)\n",
        "\n",
        "  # Train m hnh MF-IPS\n",
        "  print(\"*****Trainning MF-IPS*****\")\n",
        "  # Khi to cc tham s\n",
        "  propensities = propensity_movie_df\n",
        "  propensities_desc = \"IPS\"\n",
        "  data = Files(observed_movielen, propensities)\n",
        "  metric = MSE\n",
        "  raw_metric = 'MSE'\n",
        "  # Train m hnh\n",
        "  completed_rating_ips = learn(data, my_logger, lambdas=lambdas, numDims=numDims, metric=metric, approach=\"IPS\",\n",
        "          seed=seed, raw_metric='MSE', output_name = completed, propensities_desc=propensities_desc)\n",
        "  \n",
        "  # Test m hnh MF-Naive\n",
        "  for metric in ['MSE', 'MAE']:\n",
        "    if metric == 'MSE':\n",
        "      metricValue = MSE(remain_movielen, completed_rating_ips, None)[0]\n",
        "      result_MSE.append(metricValue)\n",
        "    else:\n",
        "      metricValue = MAE(remain_movielen, completed_rating_ips, None)[0]\n",
        "      result_MAE.append(metricValue)\n",
        "\n",
        "  return result_MSE, result_MAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW7NEerSwJJd"
      },
      "source": [
        "#### Train vi nhiu alpha khc nhau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "u8E3_d58Lo3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2512e1-1a68-484a-c257-e67f71338693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k:  0.5109913052373358\n",
            "alpha:  0.0625\n",
            "*****Trainning MF-Naive*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: naive (uniform)\n",
            "Split 79438 observations into folds. Fold sizes: [19859, 19859, 19859, 19861]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.10988772270376169342\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12633460708266544606\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.19330472045756763649\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.15757507080172941406\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.23676907438226206712\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.20488517984015120049\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.109636459561894699584\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12916009880099786987\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.19637260124437017548\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.15993470253942319562\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.2411230473137173213\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.2083035891291690758\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.10610179834367641159\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.1287095689059908863\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.19127251629498758286\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.1559622201027447755\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.23423722394194937082\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.20265734198293396783\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.11145612425104465632\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.13169051658545088622\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.19573174555942083679\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.15934255953229296333\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.24014675029664169834\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.20752965619777120223\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.10927052621509437\n",
            "\t(1, 20, -1, 'Regularized'): 0.12897369784377627\n",
            "\t(10, 10, -1, 'Regularized'): 0.19417039588908655\n",
            "\t(10, 20, -1, 'Regularized'): 0.15820363824404757\n",
            "\t(25, 10, -1, 'Regularized'): 0.2380690239836426\n",
            "\t(25, 20, -1, 'Regularized'): 0.20584394178750637\n",
            "Done.\n",
            "*****Trainning MF-IPS*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79438 observations into folds. Fold sizes: [19859, 19859, 19859, 19861]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 1.088105727209342468\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 1.1846537355197931365\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 1.1058214346446559992\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 1.0540710743188735931\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 1.1380095376665740721\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 1.12464769496770539\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 1.486379057556936348\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 1.6011741127852849711\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 1.5146410138089910205\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 1.4241748971121768358\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 1.5811703339867850348\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 1.5511029935732495316\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 1.0130189388118826549\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 1.0815109409813474919\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 1.0625774704703283269\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.9895984328655241671\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 1.1240032834486570729\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 1.0899595618805012043\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 1.3333987389112393698\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 1.4479639555255484624\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 1.3585115660038657871\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 1.29323633838216685\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 1.4143467286052611257\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 1.3875668744680442543\n",
            "Retraining with best hyperparameter values: (10, 20, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 1.23022561562235\n",
            "\t(1, 20, -1, 'Regularized'): 1.3288256862029935\n",
            "\t(10, 10, -1, 'Regularized'): 1.2603878712319603\n",
            "\t(10, 20, -1, 'Regularized'): 1.1902701856696853\n",
            "\t(25, 10, -1, 'Regularized'): 1.3143824709268193\n",
            "\t(25, 20, -1, 'Regularized'): 1.2883192812223752\n",
            "Done.\n",
            "k:  0.45226173057946856\n",
            "alpha:  0.125\n",
            "*****Trainning MF-Naive*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: naive (uniform)\n",
            "Split 79438 observations into folds. Fold sizes: [19859, 19859, 19859, 19861]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.12806255491396678071\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.1509969128492404063\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.25735226944184349\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19933404072948151682\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.33818230038898902825\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.2783671618049410399\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.124430686733960935325\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.14472343641353352645\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.2508952286079155926\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19498351564991410432\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.32895924951137464547\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.27095324065731027434\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.12554176344847156294\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.14575877254260579107\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.2535789862816967195\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19652339290335593752\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.3333549083521077081\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.27425492952558377124\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.12300402038630211773\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.14420760149552950359\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.25209341465968087396\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19319286356689934964\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.3329510195106022269\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.2731059985706915606\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.12525975637067535\n",
            "\t(1, 20, -1, 'Regularized'): 0.1464216808252273\n",
            "\t(10, 10, -1, 'Regularized'): 0.25347997474778416\n",
            "\t(10, 20, -1, 'Regularized'): 0.19600845321241273\n",
            "\t(25, 10, -1, 'Regularized'): 0.3333618694407684\n",
            "\t(25, 20, -1, 'Regularized'): 0.2741703326396317\n",
            "Done.\n",
            "*****Trainning MF-IPS*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79438 observations into folds. Fold sizes: [19859, 19859, 19859, 19861]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.51499063931403338447\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.5697535195668515638\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.619744455733978358\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.54782827124597664644\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.7351646847638909196\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.65318060546312329504\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.4671330490530510591\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.5151965602436420993\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.5462433003869569125\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.48334241345087186246\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.66009168025479157763\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.5776561886541176718\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.52179954367426847114\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.5725752956595036715\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.57853693284407008255\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.51705229286341200393\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.6840169191461005535\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.6080037350929789334\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.46384246313604258474\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.5156964667282683065\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.54687592247653435754\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.48145670727442516838\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.6556267372237335755\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.57716267359624290074\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.4919414237943489\n",
            "\t(1, 20, -1, 'Regularized'): 0.5433054605495664\n",
            "\t(10, 10, -1, 'Regularized'): 0.5728501528603849\n",
            "\t(10, 20, -1, 'Regularized'): 0.5074199212086714\n",
            "\t(25, 10, -1, 'Regularized'): 0.6837250053471291\n",
            "\t(25, 20, -1, 'Regularized'): 0.6040008007016157\n",
            "Done.\n",
            "k:  0.3400986204482767\n",
            "alpha:  0.25\n",
            "*****Trainning MF-Naive*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: naive (uniform)\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13993017386701996255\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.16325937969166189048\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3232453759107858953\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.2303945340916829819\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.47618769573500715903\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3601759540787639021\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13616802010606380344\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.15777718318451045117\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.31548035665005743283\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22268932853873303989\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.4694984595218315744\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3526534201233076797\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13467388423684254289\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.1585453144778126797\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3141266106480426393\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22198523285075402942\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.46951417414433919032\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.35151951672450175058\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13107488059684091724\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.15960357486286198593\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3089614652937681385\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.21713411507797625453\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.46382981504428292665\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.34635143564228199864\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.1354617397016918\n",
            "\t(1, 20, -1, 'Regularized'): 0.15979636305421174\n",
            "\t(10, 10, -1, 'Regularized'): 0.31545345212566356\n",
            "\t(10, 20, -1, 'Regularized'): 0.22305080263978655\n",
            "\t(25, 10, -1, 'Regularized'): 0.4697575361113652\n",
            "\t(25, 20, -1, 'Regularized'): 0.35267508164221384\n",
            "Done.\n",
            "*****Trainning MF-IPS*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79439 observations into folds. Fold sizes: [19859, 19859, 19859, 19862]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.18910339043495449712\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.20639047347749527938\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.34327121884896270114\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24912579022211296476\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5020939644848699007\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37937731585169115608\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17746633796754044089\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.18968417016545980942\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3395035657156634486\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.24452569862855851653\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.4985445440420465388\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3753747294859378613\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.17372745670547428192\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.1904942204242848944\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32894146100671479134\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.23552312519242457577\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.48987894023771483629\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3652422091811816003\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.16813384692551097295\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.18028174086379514802\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32368419366030963394\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22870107884507300607\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.48638210781242726183\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.36165120942473263105\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.17710775800837003\n",
            "\t(1, 20, -1, 'Regularized'): 0.19171265123275877\n",
            "\t(10, 10, -1, 'Regularized'): 0.33385010980791263\n",
            "\t(10, 20, -1, 'Regularized'): 0.23946892322204227\n",
            "\t(25, 10, -1, 'Regularized'): 0.49422488914426466\n",
            "\t(25, 20, -1, 'Regularized'): 0.3704113659858858\n",
            "Done.\n",
            "k:  0.1750225146696499\n",
            "alpha:  0.5\n",
            "*****Trainning MF-Naive*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: naive (uniform)\n",
            "Split 79437 observations into folds. Fold sizes: [19859, 19859, 19859, 19860]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13384756227124750068\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.16362993443214249819\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3249725831891399497\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22215814380917374067\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.52918044451126685946\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3698019822431803978\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13583974084196032116\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.1616988021483809578\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32280278413350815223\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.21789247899010655602\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.5267781807000821399\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3674038001471710212\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13843406032989841218\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.1621375435191844379\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32857171480633577652\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.22433680503720632507\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.53226706828222240136\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.37343777486935976725\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.13666233770349544276\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.1598446633631643428\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.32131177628320442953\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.21642734872092412377\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.52690271193664466585\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3664569358989433445\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.13619592528665042\n",
            "\t(1, 20, -1, 'Regularized'): 0.16182773586571803\n",
            "\t(10, 10, -1, 'Regularized'): 0.3244147146030471\n",
            "\t(10, 20, -1, 'Regularized'): 0.2202036941393527\n",
            "\t(25, 10, -1, 'Regularized'): 0.528782101357554\n",
            "\t(25, 20, -1, 'Regularized'): 0.3692751232896636\n",
            "Done.\n",
            "*****Trainning MF-IPS*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79437 observations into folds. Fold sizes: [19859, 19859, 19859, 19860]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.11215170265061726896\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12329028155045616237\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.304923832299518408\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.2054702068770485937\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.47021113180041929853\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.34133128016346996135\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.10922001840031369769\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.119826340683190833235\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.30431319307437558957\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.20275816282754296834\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.47272506188976019464\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.34273575870511330997\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.112325700988361226916\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.120624747797269265274\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3041588640027046298\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.20386525152216749639\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.47164166894423680657\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.34225390226766677965\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.109809622113129596125\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.11902335936313483646\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.30135487036992510997\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19969712483310761794\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.47089456161937230785\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.34004331967725056528\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.11087676103810545\n",
            "\t(1, 20, -1, 'Regularized'): 0.12069118234851278\n",
            "\t(10, 10, -1, 'Regularized'): 0.3036876899366309\n",
            "\t(10, 20, -1, 'Regularized'): 0.20294768651496667\n",
            "\t(25, 10, -1, 'Regularized'): 0.47136810606344715\n",
            "\t(25, 20, -1, 'Regularized'): 0.3415910652033751\n",
            "Done.\n",
            "k:  0.050082780308752274\n",
            "alpha:  1\n",
            "*****Trainning MF-Naive*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: naive (uniform)\n",
            "Split 79437 observations into folds. Fold sizes: [19859, 19859, 19859, 19860]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.11436307265599413376\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12352846610041059361\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.29789973719749647573\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19671191355566469706\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.46167749428391978628\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3356019925394581737\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.11729112055506528142\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12117877485536846032\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.301850303916970758\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19947326200598865942\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.46712033878060737162\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.34012185154224440484\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.121470481724398592715\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12538820853077359004\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3052840421698848388\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.2033675332267267716\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.46953116882437078455\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3429659448888764881\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.12297762260035088048\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.13946014540610502245\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.3132320771456113851\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.20677716371170990265\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.48612596206845065175\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.35327181785690335678\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.11902557438395221\n",
            "\t(1, 20, -1, 'Regularized'): 0.12738889872316442\n",
            "\t(10, 10, -1, 'Regularized'): 0.30456654010749085\n",
            "\t(10, 20, -1, 'Regularized'): 0.2015824681250225\n",
            "\t(25, 10, -1, 'Regularized'): 0.47111374098933717\n",
            "\t(25, 20, -1, 'Regularized'): 0.3429904017068706\n",
            "Done.\n",
            "*****Trainning MF-IPS*****\n",
            "Starting learning...\n",
            "\t-metric: MSE\n",
            "\t-lambda values: [1, 10, 25]\n",
            "\t-dimension values: [10, 20]\n",
            "\t-propensity scoring method: IPS\n",
            "Split 79437 observations into folds. Fold sizes: [19859, 19859, 19859, 19860]\n",
            "Learning on fold 0 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.1143606076360514186\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12344844565426779457\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.29789408636183844944\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19670845827368285267\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.46166889009457293328\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.33559629665955387448\n",
            "Learning on fold 1 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.117289167128003012474\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12305112642527521369\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.30184455193532919268\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.19948640981286501685\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.4671118180265823728\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.3401155528976579512\n",
            "Learning on fold 2 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.11731348405946660831\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12849374493819293305\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.30527830718257476758\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.20336161650039557957\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.46952241541923733884\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.34295928101227966082\n",
            "Learning on fold 3 \n",
            "\tLambda/NumDims: (1, 10, -1, 'Regularized'), Test Fold Score: 0.12170454749774532903\n",
            "\tLambda/NumDims: (1, 20, -1, 'Regularized'), Test Fold Score: 0.12764079493533443847\n",
            "\tLambda/NumDims: (10, 10, -1, 'Regularized'), Test Fold Score: 0.31324579798518938756\n",
            "\tLambda/NumDims: (10, 20, -1, 'Regularized'), Test Fold Score: 0.20677318967678646071\n",
            "\tLambda/NumDims: (25, 10, -1, 'Regularized'), Test Fold Score: 0.4861455183565917227\n",
            "\tLambda/NumDims: (25, 20, -1, 'Regularized'), Test Fold Score: 0.35328600042241021945\n",
            "Retraining with best hyperparameter values: (1, 10, -1, 'Regularized')\n",
            "Chosen from average cross-validation performance:\n",
            "\t(1, 10, -1, 'Regularized'): 0.11766695158031659\n",
            "\t(1, 20, -1, 'Regularized'): 0.1256585279882676\n",
            "\t(10, 10, -1, 'Regularized'): 0.30456568586623295\n",
            "\t(10, 20, -1, 'Regularized'): 0.20158241856593248\n",
            "\t(25, 10, -1, 'Regularized'): 0.4711121604742461\n",
            "\t(25, 20, -1, 'Regularized'): 0.34298928274797547\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "alphas = [0.0625,0.125,0.25,0.5, 1]\n",
        "MSE_naive = []\n",
        "MSE_IPS = []\n",
        "for alpha in alphas:\n",
        "  result_MSE, result_MAE = train_with_alpha(alpha)\n",
        "  MSE_naive.append(result_MSE[0])\n",
        "  MSE_IPS.append(result_MSE[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkVOTze9yU8I"
      },
      "source": [
        "#### Trc quan kt qu d on theo  o MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "0Sflb6aoXUFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ed5b06-81ae-439c-c7a5-e9a586010eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9320215409049297937 1.0977265133970252594\n",
            "0.84305514390331748217 0.39824485491559453445\n",
            "0.24844974592421062548 0.15234949744816172562\n",
            "0.11270237385496852981 0.09738659774196505986\n",
            "0.10836185949316395787 0.108356511396837288325\n"
          ]
        }
      ],
      "source": [
        "MSE_naive, MSE_IPS\n",
        "for i in range(len(MSE_naive)):\n",
        "  print(MSE_naive[i] , MSE_IPS[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "sM9XHVuLtuks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "55590d22-7fce-4a28-c191-c83321c21cbc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(alphas,MSE_naive, label = \"MF-naive\")\n",
        "plt.plot(alphas,MSE_IPS, label = \"MF-IPS\")\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('MSE')\n",
        "plt.title(' li trn tp d liu quan st c vi alpha thay i')\n",
        "\n",
        "# ticks = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.7]\n",
        "# plt.yticks(ticks)\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vcu0OQ7cLqEi",
        "0Bpm1mQaLvuK"
      ],
      "name": "Thesis_Movielen",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}